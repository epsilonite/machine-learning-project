{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "KThtWptSMABJ",
   "metadata": {
    "id": "KThtWptSMABJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, cohen_kappa_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9cbca42-1b58-4a78-b6a6-9b8f4d6452df",
   "metadata": {
    "id": "e9cbca42-1b58-4a78-b6a6-9b8f4d6452df"
   },
   "outputs": [],
   "source": [
    "dir = 'data/'\n",
    "modelname='nasnetmobile0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54aa3306-1122-4a48-beb1-dadcbdd70fc6",
   "metadata": {
    "id": "54aa3306-1122-4a48-beb1-dadcbdd70fc6"
   },
   "outputs": [],
   "source": [
    "def load_tfrecord_dataset(file_path):\n",
    "    # Define a function to parse the TFRecord file\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([224 * 224 * 1], tf.float32),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "\n",
    "    def _parse_function(example_proto):\n",
    "        # Parse the input tf.train.Example proto using the feature description\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        image = tf.reshape(parsed_features['image'], [224, 224, 1])\n",
    "        label = parsed_features['label']\n",
    "        return image, label\n",
    "\n",
    "    # Load and parse the dataset\n",
    "    raw_dataset = tf.data.TFRecordDataset(file_path)\n",
    "    parsed_dataset = raw_dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return parsed_dataset\n",
    "\n",
    "# Load the datasets from TFRecord files\n",
    "ds_train = load_tfrecord_dataset(f'{dir}ds_train.tfrecord')\n",
    "ds_val = load_tfrecord_dataset(f'{dir}ds_val.tfrecord')\n",
    "ds_test = load_tfrecord_dataset(f'{dir}ds_test.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "y7k_iaodN9RJ",
   "metadata": {
    "id": "y7k_iaodN9RJ"
   },
   "outputs": [],
   "source": [
    "# Preprocess the datasets\n",
    "def preprocess_dataset(dataset):\n",
    "    # Apply preprocessing using a lambda function to convert grayscale to RGB and preprocess\n",
    "    def refactor(image,label):\n",
    "        # Convert grayscale images to RGB\n",
    "        image = tf.image.grayscale_to_rgb(image)\n",
    "        # Apply preprocessing\n",
    "        image = tf.keras.applications.nasnet.preprocess_input(image)\n",
    "        return image, label\n",
    "    dataset = dataset.map(refactor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "# Apply preprocess to datasets\n",
    "ds_train = preprocess_dataset(ds_train)\n",
    "ds_val = preprocess_dataset(ds_val)\n",
    "ds_test = preprocess_dataset(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nLxG9yQIlnrY",
   "metadata": {
    "id": "nLxG9yQIlnrY"
   },
   "outputs": [],
   "source": [
    "# Batch the datasets for training and evaluation\n",
    "batch_size = 16\n",
    "ds_train = ds_train.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b02403d0-3248-4912-b14e-e9b5a73d697e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "b02403d0-3248-4912-b14e-e9b5a73d697e",
    "outputId": "c53bf2a5-094c-4f83-a645-aabded66b277"
   },
   "outputs": [],
   "source": [
    "# Build base_model\n",
    "base_model = tf.keras.applications.NASNetMobile(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "# Build the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(base_model)\n",
    "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "model.add(tf.keras.layers.Dense(3, activation='softmax')) # Multi-class classification for labels [0, 1, 2]\n",
    "# Unfreeze some layers in the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 20  # Unfreeze the last 20 layers\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "amlC-xQsrPoj",
   "metadata": {
    "id": "amlC-xQsrPoj"
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "MmPbm7jKl2p-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmPbm7jKl2p-",
    "outputId": "28dcd05c-f59a-479d-a56f-3b3fad866c0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 598ms/step - accuracy: 0.4142 - loss: 1.0934 - val_accuracy: 0.5118 - val_loss: 0.9720 - learning_rate: 1.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 385ms/step - accuracy: 0.6219 - loss: 0.8423 - val_accuracy: 0.6235 - val_loss: 0.8602 - learning_rate: 1.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 211ms/step - accuracy: 0.6526 - loss: 0.7980 - val_accuracy: 0.6235 - val_loss: 0.8045 - learning_rate: 1.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 228ms/step - accuracy: 0.6761 - loss: 0.7639 - val_accuracy: 0.6412 - val_loss: 0.7773 - learning_rate: 1.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 220ms/step - accuracy: 0.6961 - loss: 0.7346 - val_accuracy: 0.6353 - val_loss: 0.7668 - learning_rate: 1.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 245ms/step - accuracy: 0.7167 - loss: 0.7079 - val_accuracy: 0.6353 - val_loss: 0.7665 - learning_rate: 1.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 217ms/step - accuracy: 0.7211 - loss: 0.6828 - val_accuracy: 0.6412 - val_loss: 0.7735 - learning_rate: 1.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 215ms/step - accuracy: 0.7380 - loss: 0.6587 - val_accuracy: 0.6294 - val_loss: 0.7826 - learning_rate: 1.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 204ms/step - accuracy: 0.7595 - loss: 0.6353 - val_accuracy: 0.6176 - val_loss: 0.7933 - learning_rate: 1.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 194ms/step - accuracy: 0.7703 - loss: 0.6125 - val_accuracy: 0.6000 - val_loss: 0.8028 - learning_rate: 1.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 214ms/step - accuracy: 0.7775 - loss: 0.5900 - val_accuracy: 0.5824 - val_loss: 0.8130 - learning_rate: 1.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 205ms/step - accuracy: 0.7875 - loss: 0.5643 - val_accuracy: 0.5941 - val_loss: 0.8009 - learning_rate: 5.0000e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 212ms/step - accuracy: 0.7911 - loss: 0.5527 - val_accuracy: 0.5941 - val_loss: 0.7968 - learning_rate: 5.0000e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 215ms/step - accuracy: 0.7947 - loss: 0.5413 - val_accuracy: 0.6059 - val_loss: 0.7924 - learning_rate: 5.0000e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 212ms/step - accuracy: 0.8003 - loss: 0.5300 - val_accuracy: 0.6176 - val_loss: 0.7884 - learning_rate: 5.0000e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 218ms/step - accuracy: 0.8102 - loss: 0.5188 - val_accuracy: 0.6235 - val_loss: 0.7843 - learning_rate: 5.0000e-05\n",
      "Training time: 390.86 seconds\n"
     ]
    }
   ],
   "source": [
    "# Measure training time\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data = ds_val,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, lr_scheduler])\n",
    "# Measure and print runtime\n",
    "print(f\"Training time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d39e7-e1ac-41f6-8c30-0d2f599621e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze some layers in the base model for fine-tuning\n",
    "base_model.trainable = True\n",
    "fine_tune_at = len(base_model.layers) - 20  # Unfreeze the last 20 layers\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(.00025),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1dae98-b02d-4209-8831-aeeb1cbdf11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure training time\n",
    "start_time = time.time()\n",
    "# Train the model\n",
    "history_fine = model.fit(\n",
    "    ds_train,\n",
    "    validation_data = ds_val,\n",
    "    epochs=100,\n",
    "    callbacks=[early_stopping, lr_scheduler])\n",
    "# Measure and print runtime\n",
    "print(f\"Training time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ZMphieQyl681",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZMphieQyl681",
    "outputId": "646bfb2b-5e2c-42c1-c79e-775e222302ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 192ms/step - accuracy: 0.9351 - loss: 0.3264\n",
      "Test Loss: 0.350116103887558, Test Accuracy: 0.9117646813392639\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "results = model.evaluate(ds_test)\n",
    "print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Hbsgt6iyq0AC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hbsgt6iyq0AC",
    "outputId": "b3b45793-8952-4dad-f7ad-7def15e59807"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 13s/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "# Generate predictions for additional metrics\n",
    "for images, labels in ds_test:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c7a5d46-a791-4adb-a807-a67d57c29752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b25ch\\anaconda3\\envs\\dev\\lib\\contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "# Convert lists to NumPy arrays for metric calculations\n",
    "y_true_np = np.array(y_true)\n",
    "y_pred_np = np.array(y_pred)\n",
    "y_true_bin = label_binarize(y_true, classes=[0, 1, 2])\n",
    "y_prob = model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "OwtHxAiba9sh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwtHxAiba9sh",
    "outputId": "333ebeb2-722d-4a0b-a8c0-97e2343a6c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1   2\n",
      "0  75  0   9\n",
      "1   0  7   2\n",
      "2   4  0  73\n",
      "   test_loss  valid_accurancy  precision    recall        f1   roc_auc  \\\n",
      "0   0.350116         0.911765   0.901099  0.953488  0.926554  0.908983   \n",
      "\n",
      "     kappa  \n",
      "0  0.83792  \n"
     ]
    }
   ],
   "source": [
    "# Calculate sklearn confusion matrix and classification report\n",
    "conf_matrix = confusion_matrix(y_true_np, y_pred_np)\n",
    "df_matrix = pd.DataFrame(conf_matrix)\n",
    "df_report = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose()\n",
    "print(df_matrix)\n",
    "# Calculate additional keras metrics\n",
    "precision = tf.keras.metrics.Precision()(y_true, y_pred).numpy()\n",
    "recall = tf.keras.metrics.Recall()(y_true, y_pred).numpy()\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "roc_auc = roc_auc_score(y_true, tf.keras.utils.to_categorical(y_pred, 3), multi_class='ovr')\n",
    "df_metrics = pd.DataFrame({'test_loss': [results[0]],\n",
    "                           'valid_accurancy': [results[1]],\n",
    "                           'precision': [precision],\n",
    "                           'recall': [recall],\n",
    "                           'f1': [2*(precision*recall) / (precision+recall)],\n",
    "                           'roc_auc': [roc_auc],\n",
    "                           'kappa': [cohen_kappa_score(y_true, y_pred)] })\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "xIfDo6kma9zD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "xIfDo6kma9zD",
    "outputId": "093ff54f-d701-4420-af5d-492f84606f1f"
   },
   "outputs": [],
   "source": [
    "# Extracting accuracy and loss values\n",
    "df_history = pd.DataFrame(history.history)\n",
    "# Generate the classification report and convert the report to a DataFrame\n",
    "df_report = pd.DataFrame(classification_report(y_true, y_pred, output_dict=True)).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e46e49f-9e8c-46d5-91da-04fb6eaacc55",
   "metadata": {},
   "source": [
    "### Export Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4d81ede-4651-4391-b33b-61c57f8a9361",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'outputs/y_true_np-{modelname}.npy',y_true_np)\n",
    "np.save(f'outputs/y_pred_np-{modelname}.npy',y_pred_np)\n",
    "np.save(f'outputs/y_true_bin-{modelname}.npy',y_true_bin)\n",
    "np.save(f'outputs/y_prob-{modelname}.npy',y_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "A6ifLalobBQn",
   "metadata": {
    "id": "A6ifLalobBQn"
   },
   "outputs": [],
   "source": [
    "df_matrix.to_csv(f'outputs/matrix-{modelname}.csv')\n",
    "df_report.to_csv(f'outputs/report-{modelname}.csv')\n",
    "df_metrics.to_csv(f'outputs/metrics-{modelname}.csv')\n",
    "df_history.to_csv(f'outputs/history-{modelname}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8320465-4398-4154-9a86-b703fa1d535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "model.save(f\"models/{modelname}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd313b4-23c0-4fc8-b258-4018a02f1b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
