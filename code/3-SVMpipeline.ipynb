{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001dab37-6e46-4d69-b37c-7dc7f6eb19df",
   "metadata": {},
   "source": [
    "based on https://pmc.ncbi.nlm.nih.gov/articles/PMC8871265/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6039ea8-61a3-4a4c-880f-e813425a9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV2, NASNetMobile\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca82cc-b3a1-443d-a12e-e8325c973168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to save model checkpoints\n",
    "mobilenet_weights_path = 'models/mobilenet_weights.h5'\n",
    "nasnet_weights_path = 'models/nasnet_weights.h5'\n",
    "\n",
    "# Load MobileNetV2 and NASNetMobile without the top layers\n",
    "mobilenet_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "nasnet_base = NASNetMobile(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add Global Average Pooling to convert the convolutional feature maps to a 1D vector\n",
    "mobilenet_model = Model(inputs=mobilenet_base.input, outputs=GlobalAveragePooling2D()(mobilenet_base.output))\n",
    "nasnet_model = Model(inputs=nasnet_base.input, outputs=GlobalAveragePooling2D()(nasnet_base.output))\n",
    "\n",
    "# Load weights if available\n",
    "if os.path.exists(mobilenet_weights_path):\n",
    "    print(\"Loading MobileNetV2 weights from checkpoint...\")\n",
    "    mobilenet_model.load_weights(mobilenet_weights_path)\n",
    "else:\n",
    "    print(\"No MobileNetV2 weights found. Proceeding without loading.\")\n",
    "\n",
    "if os.path.exists(nasnet_weights_path):\n",
    "    print(\"Loading NASNetMobile weights from checkpoint...\")\n",
    "    nasnet_model.load_weights(nasnet_weights_path)\n",
    "else:\n",
    "    print(\"No NASNetMobile weights found. Proceeding without loading.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6d3df3-157d-4de0-b09e-9e670be5a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator instance with data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=90,          # Randomly rotate images in multiples of 90 degrees\n",
    "    zoom_range=0.5,            # Randomly zoom images by up to 50%\n",
    "    horizontal_flip=True,       # Randomly flip images horizontally\n",
    "    vertical_flip=True          # Randomly flip images vertically\n",
    ")\n",
    "\n",
    "# Generate batches from the NumPy array along with labels\n",
    "generator = datagen.flow(\n",
    "    images,\n",
    "    labels,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# Example to iterate through generated batches\n",
    "for batch_images, batch_labels in generator:\n",
    "    # Use the batch for training, prediction, etc.\n",
    "    print(\"Generated batch shape:\", batch_images.shape)\n",
    "    print(\"Generated labels shape:\", batch_labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ced1c6-e04c-406e-8bab-85968bf08108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features using both models\n",
    "mobilenet_features = mobilenet_model.predict(train_generator)\n",
    "nasnet_features = nasnet_model.predict(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779ca33-5b5f-45f7-ba27-945f8e4b31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights after feature extraction for future resumption\n",
    "mobilenet_model.save_weights(mobilenet_weights_path)\n",
    "nasnet_model.save_weights(nasnet_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274e67d-6ff8-4259-9be2-42be8d160089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse features by concatenating them\n",
    "fused_features = np.concatenate([mobilenet_features, nasnet_features], axis=1)\n",
    "labels = train_generator.classes\n",
    "\n",
    "# Split the data into 80% training and 20% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(fused_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features and train an SVM model\n",
    "scaler = StandardScaler()\n",
    "svm_model = SVC(kernel='poly', degree=3, C=1.0, probability=True)\n",
    "\n",
    "# Combine the scaler and SVM into a pipeline\n",
    "svm_pipeline = make_pipeline(scaler, svm_model)\n",
    "\n",
    "# Check if a previously trained model exists to resume training\n",
    "model_path = 'cubic_svm_model.pkl'\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading existing SVM model to resume training...\")\n",
    "    svm_pipeline = joblib.load(model_path)\n",
    "else:\n",
    "    print(\"No existing SVM model found. Training a new model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b60717-53d8-494b-843e-baf269962f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SVM model using the training set\n",
    "start_time = time.time()\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae5bdd-45ea-4534-b7ab-8e3c6dc44316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained SVM model for future use\n",
    "joblib.dump(svm_pipeline, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61755e67-a379-4c0c-b23a-3909770dd0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example evaluation on the test set\n",
    "predictions = svm_pipeline.predict(X_test)\n",
    "prediction_probabilities = svm_pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700298a0-b55b-4c5f-a78f-6700f7063adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, predictions) * 100\n",
    "precision = precision_score(y_test, predictions) * 100\n",
    "recall = recall_score(y_test, predictions) * 100\n",
    "f1 = f1_score(y_test, predictions) * 100\n",
    "auc = roc_auc_score(y_test, prediction_probabilities)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "kappa = cohen_kappa_score(y_test, predictions)\n",
    "specificity = conf_matrix[0][0] / (conf_matrix[0][0] + conf_matrix[0][1]) * 100 if (conf_matrix[0][0] + conf_matrix[0][1]) != 0 else 0\n",
    "\n",
    "print(f'Test Accuracy (%): {accuracy:.2f}')\n",
    "print(f'Precision (%): {precision:.2f}')\n",
    "print(f'Sensitivity (Recall) (%): {recall:.2f}')\n",
    "print(f'F1-Score (%): {f1:.2f}')\n",
    "print(f'AUC: {auc:.2f}')\n",
    "print(f'Specificity (%): {specificity:.2f}')\n",
    "print(f'Cohen Kappa: {kappa:.2f}')\n",
    "print(f'Training Time (s): {training_time:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
