{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e27db-c2ae-42a6-8a85-f0901eb33f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Reshape, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, cohen_kappa_score, confusion_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb5518-d51b-4fbd-b11e-14247e4ee754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata for LSTM input\n",
    "metadata = pd.read_csv('/mnt/data/df_train.csv')\n",
    "\n",
    "# Define CNN model for feature extraction using ResNet50\n",
    "def build_cnn(input_shape):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    cnn_model = Model(base_model.input, x)\n",
    "    return cnn_model\n",
    "\n",
    "# Define LSTM model for semantic feature extraction\n",
    "def build_lstm(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = LSTM(64, return_sequences=False)(inputs)\n",
    "    lstm_model = Model(inputs, x)\n",
    "    return lstm_model\n",
    "\n",
    "# Combined model\n",
    "def build_combined_model(cnn_input_shape, lstm_input_shape):\n",
    "    cnn_model = build_cnn(cnn_input_shape)\n",
    "    lstm_model = build_lstm(lstm_input_shape)\n",
    "\n",
    "    combined_input = tf.keras.layers.Concatenate()([cnn_model.output, lstm_model.output])\n",
    "    x = Dense(128, activation='relu')(combined_input)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model([cnn_model.input, lstm_model.input], x)\n",
    "    return model\n",
    "\n",
    "# Input shapes for CNN and LSTM\n",
    "cnn_input_shape = (224, 224, 3)  # ResNet50 requires 224x224 RGB images\n",
    "lstm_input_shape = (metadata.shape[1],)  # Number of features in metadata.csv\n",
    "\n",
    "# Build and compile the model\n",
    "model = build_combined_model(cnn_input_shape, lstm_input_shape)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Checkpoint callback for training resumption\n",
    "checkpoint_path = \"model_checkpoint.h5\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Load weights if a checkpoint exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "    print(\"Loaded weights from checkpoint\")\n",
    "\n",
    "# Data preparation\n",
    "# Assuming 'images' is a NumPy array of shape (num_samples, 224, 224, 3)\n",
    "# and 'labels' is a NumPy array of shape (num_samples,)\n",
    "images = np.random.rand(100, 224, 224, 3)  # Replace with actual image data\n",
    "labels = np.random.randint(0, 3, size=(100,))  # Example labels: 0 - Normal, 1 - Benign, 2 - Malignant\n",
    "\n",
    "# One-hot encode the labels\n",
    "labels = to_categorical(labels, num_classes=3)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train_img, X_val_img, X_train_meta, X_val_meta, y_train, y_val = train_test_split(\n",
    "    images, metadata.values, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Data augmentation for images\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,  # Normalize to [0, 1] range\n",
    "    rotation_range=90,\n",
    "    zoom_range=0.5,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "batch_size = 8\n",
    "epochs = 10\n",
    "\n",
    "train_img_generator = datagen.flow(X_train_img, y_train, batch_size=batch_size)\n",
    "val_img_generator = datagen.flow(X_val_img, y_val, batch_size=batch_size)\n",
    "\n",
    "# Training and validation loop with metadata included manually\n",
    "history = model.fit(\n",
    "    [X_train_img, X_train_meta],\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([X_val_img, X_val_meta], y_val),\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Feature extraction from the combined model\n",
    "feature_extractor = Model(inputs=model.input, outputs=model.layers[-3].output)  # Extract features from the Dense(128) layer\n",
    "\n",
    "# Assuming we want to extract features from the training data\n",
    "combined_features = feature_extractor.predict([X_train_img, X_train_meta], batch_size=batch_size)\n",
    "\n",
    "# Ensemble learning using RandomForest and Boosting\n",
    "# Here we assume `combined_features` is obtained after training the CNN-LSTM model and extracting features\n",
    "labels = np.argmax(y_train, axis=1)  # Convert one-hot encoded labels to single class labels\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(combined_features, labels)\n",
    "\n",
    "# XGBoost Classifier\n",
    "xgb_classifier = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_classifier.fit(combined_features, labels)\n",
    "\n",
    "# Ensemble prediction (averaging the probabilities)\n",
    "def ensemble_predict(feature_set):\n",
    "    rf_preds = rf_classifier.predict_proba(feature_set)\n",
    "    xgb_preds = xgb_classifier.predict_proba(feature_set)\n",
    "    final_preds = (rf_preds + xgb_preds) / 2\n",
    "    return np.argmax(final_preds, axis=1)\n",
    "\n",
    "# Example prediction\n",
    "example_features = np.random.rand(5, combined_features.shape[1])  # Example feature set for prediction\n",
    "predictions = ensemble_predict(example_features)\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "# Evaluate model using additional metrics\n",
    "# Assuming validation features are extracted similarly as training features\n",
    "combined_val_features = feature_extractor.predict([X_val_img, X_val_meta], batch_size=batch_size)\n",
    "\n",
    "# Make predictions on validation data\n",
    "val_predictions = ensemble_predict(combined_val_features)\n",
    "val_labels = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(val_labels, val_predictions)\n",
    "precision = precision_score(val_labels, val_predictions, average='weighted')\n",
    "recall = recall_score(val_labels, val_predictions, average='weighted')\n",
    "f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "roc_auc = roc_auc_score(to_categorical(val_labels, num_classes=3), \n",
    "                        to_categorical(val_predictions, num_classes=3), \n",
    "                        multi_class='ovr')\n",
    "kappa = cohen_kappa_score(val_labels, val_predictions)\n",
    "\n",
    "# Confusion matrix for specificity calculation\n",
    "conf_matrix = confusion_matrix(val_labels, val_predictions)\n",
    "specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1:].sum()) if conf_matrix.shape[0] > 1 else 0.0\n",
    "\n",
    "print(f\"Training Accuracy: {history.history['accuracy'][-1]}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall (Sensitivity): {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Cohen's Kappa: {kappa}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
