{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "885efc0f-e3bc-4f55-b289-67d5f084bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdecc54c-c03e-4fc7-9f52-a321f85a36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "dir = 'data/cbis-ddsm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeaf8daf-0cb6-4b08-abdf-37707fa4ee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>pathology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>P_02092_LEFT_MLO_1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              identifier  pathology\n",
       "1695  P_02092_LEFT_MLO_1          2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import labels\n",
    "df = pd.read_csv(f'{dir}mass-labels.csv')\n",
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48682e29-1842-432d-a6dd-5f0b85ffddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import npy data\n",
    "img_npys = [np.load(f'{dir}mass-npy/{x}.npy') for x in df.identifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b3cd909-917f-4158-a70e-5a8c21275d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for preprocessing\n",
    "# Resize Images from import to shape (224,224,3)\n",
    "def resize(img_npys, size=(224, 224)):\n",
    "    resized_imgs = [tf.image.resize(np.stack([img] * 3, axis=-1), size).numpy() for img in img_npys]\n",
    "    return resized_imgs\n",
    "# Create Dataset from imports, and boolean for data augmentation\n",
    "def create_dataset(imgs, labels, augment=False):\n",
    "    # Convert lists of numpy arrays and labels into tf.data.Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((imgs, labels))\n",
    "    # Data augmentation function\n",
    "    def augment_image(image, label):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "        image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "        return image, label\n",
    "    # Apply data augmentation to the training dataset only\n",
    "    if augment: dataset = dataset.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60f17a60-0365-4650-b231-7b560a453176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images\n",
    "imgs = resize(img_npys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51f00ce7-440a-466d-9d63-978c079febfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Images\n",
    "imgs = tf.keras.applications.densenet.preprocess_input(np.array(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0518ec04-fea5-48b7-a36e-6d53657a80e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1696, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e8888d-3e0f-465c-a2a7-5047a5599ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "ds = create_dataset([*imgs], df.pathology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ad45f3-887d-4ffc-984a-50d32b634e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "ds_rnd = ds.shuffle(buffer_size=len(imgs), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2accaba-6274-4e03-b58a-121c5d5b6cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1696 1356 170\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sizes of training, validation, and test sets\n",
    "dim = len(imgs)\n",
    "dim1 = round(0.1*dim)\n",
    "dim8 = dim-2*dim1\n",
    "print(dim,dim8,dim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d9b998d-eb9f-41fd-99a1-3902c3187ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "ds_train = ds_rnd.take(dim8)\n",
    "ds_r = ds_rnd.skip(dim8)\n",
    "ds_val = ds_r.take(dim1)\n",
    "ds_test = ds_r.skip(dim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6d7c0b9-292b-4a47-8a49-5c0c3d859860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the datasets for training and evaluation\n",
    "batch_size = 16  # Reduced batch size for radiology images\n",
    "ds_train = ds_train.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaca737f-6ff3-4442-8871-e19af7907a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Image shape: (16, 224, 224, 3), Label: [2 2 0 2 0 2 1 2 2 2 0 0 1 2 2 0]\n",
      "Sample 2: Image shape: (16, 224, 224, 3), Label: [2 0 2 1 2 2 2 2 0 2 0 2 2 0 2 0]\n",
      "Sample 3: Image shape: (16, 224, 224, 3), Label: [0 2 0 0 0 0 0 0 0 2 0 0 1 2 0 0]\n",
      "Sample 4: Image shape: (16, 224, 224, 3), Label: [2 2 0 2 0 0 0 0 0 0 0 2 1 2 2 0]\n",
      "Sample 5: Image shape: (16, 224, 224, 3), Label: [2 2 2 2 0 2 0 0 2 0 0 1 2 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "for i, (image, label) in enumerate(ds_train.take(5)):\n",
    "        print(f\"Sample {i+1}: Image shape: {image.shape}, Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d03ab0-23fe-455f-8039-56a51c8feb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build base model\n",
    "base_model = tf.keras.applications.DenseNet121(input_shape=(224, 224, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34565d0f-afc7-49c1-aa93-ef68fcfb5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers for classification\n",
    "global_avg_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "dropout_layer = tf.keras.layers.Dropout(0.3)  # Add dropout to prevent overfitting\n",
    "output_layer = tf.keras.layers.Dense(3, activation='softmax')  # Multi-class classification for labels [0, 1, 2]\n",
    "# Assemble the model\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    global_avg_layer,\n",
    "    dropout_layer,\n",
    "    output_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ed97ea3-1c14-4e64-95a4-10d4df14b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with a lower learning rate\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91a4cd34-08f3-4d83-8bc9-059b8ca763f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:35\u001b[0m 13s/step - accuracy: 0.5000 - loss: 1.1597Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 273ms/step - accuracy: 0.5312 - loss: 1.1166Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 275ms/step - accuracy: 0.5278 - loss: 1.1120Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 274ms/step - accuracy: 0.5208 - loss: 1.1210Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 272ms/step - accuracy: 0.5217 - loss: 1.1199Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 271ms/step - accuracy: 0.5163 - loss: 1.1252Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 270ms/step - accuracy: 0.5076 - loss: 1.1327Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 270ms/step - accuracy: 0.5037 - loss: 1.1362Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 269ms/step - accuracy: 0.5010 - loss: 1.1401Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 269ms/step - accuracy: 0.4984 - loss: 1.1430Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 268ms/step - accuracy: 0.4954 - loss: 1.1470Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 268ms/step - accuracy: 0.4932 - loss: 1.1492Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 268ms/step - accuracy: 0.4919 - loss: 1.1504Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 268ms/step - accuracy: 0.4906 - loss: 1.1524Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 268ms/step - accuracy: 0.4901 - loss: 1.1534Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 267ms/step - accuracy: 0.4900 - loss: 1.1543Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 267ms/step - accuracy: 0.4895 - loss: 1.1551Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 267ms/step - accuracy: 0.4887 - loss: 1.1574Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 267ms/step - accuracy: 0.4876 - loss: 1.1602Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 268ms/step - accuracy: 0.4863 - loss: 1.1624Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 268ms/step - accuracy: 0.4850 - loss: 1.1648Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 268ms/step - accuracy: 0.4833 - loss: 1.1675Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 268ms/step - accuracy: 0.4818 - loss: 1.1696Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 267ms/step - accuracy: 0.4807 - loss: 1.1715Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 267ms/step - accuracy: 0.4798 - loss: 1.1733Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 267ms/step - accuracy: 0.4788 - loss: 1.1753Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 267ms/step - accuracy: 0.4776 - loss: 1.1774Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 267ms/step - accuracy: 0.4764 - loss: 1.1795Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - accuracy: 0.4751 - loss: 1.1817Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - accuracy: 0.4736 - loss: 1.1840Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - accuracy: 0.4723 - loss: 1.1862Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 266ms/step - accuracy: 0.4709 - loss: 1.1883Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 266ms/step - accuracy: 0.4696 - loss: 1.1903Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 266ms/step - accuracy: 0.4684 - loss: 1.1921Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 266ms/step - accuracy: 0.4672 - loss: 1.1940Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 266ms/step - accuracy: 0.4662 - loss: 1.1957Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 266ms/step - accuracy: 0.4652 - loss: 1.1973Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 266ms/step - accuracy: 0.4643 - loss: 1.1986Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 266ms/step - accuracy: 0.4634 - loss: 1.1998Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 266ms/step - accuracy: 0.4624 - loss: 1.2011Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 266ms/step - accuracy: 0.4615 - loss: 1.2021Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 266ms/step - accuracy: 0.4608 - loss: 1.2029Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 266ms/step - accuracy: 0.4602 - loss: 1.2035Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 266ms/step - accuracy: 0.4595 - loss: 1.2041Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 266ms/step - accuracy: 0.4590 - loss: 1.2046Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 266ms/step - accuracy: 0.4585 - loss: 1.2051Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 266ms/step - accuracy: 0.4581 - loss: 1.2055Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 266ms/step - accuracy: 0.4578 - loss: 1.2059 Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 266ms/step - accuracy: 0.4574 - loss: 1.2062Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 266ms/step - accuracy: 0.4570 - loss: 1.2066Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 266ms/step - accuracy: 0.4567 - loss: 1.2070Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - accuracy: 0.4565 - loss: 1.2073Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - accuracy: 0.4563 - loss: 1.2074Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - accuracy: 0.4561 - loss: 1.2075Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.4559 - loss: 1.2075Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 266ms/step - accuracy: 0.4557 - loss: 1.2076Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 265ms/step - accuracy: 0.4556 - loss: 1.2076Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 265ms/step - accuracy: 0.4554 - loss: 1.2077Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.4553 - loss: 1.2078Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.4551 - loss: 1.2079Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.4550 - loss: 1.2079Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 265ms/step - accuracy: 0.4549 - loss: 1.2079Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 265ms/step - accuracy: 0.4548 - loss: 1.2078Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 265ms/step - accuracy: 0.4546 - loss: 1.2078Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 265ms/step - accuracy: 0.4545 - loss: 1.2077Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 265ms/step - accuracy: 0.4544 - loss: 1.2077Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.4543 - loss: 1.2076Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.4541 - loss: 1.2075Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.4540 - loss: 1.2074Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 264ms/step - accuracy: 0.4539 - loss: 1.2073Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 265ms/step - accuracy: 0.4538 - loss: 1.2073Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 264ms/step - accuracy: 0.4536 - loss: 1.2072Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 264ms/step - accuracy: 0.4535 - loss: 1.2071Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - accuracy: 0.4534 - loss: 1.2070Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - accuracy: 0.4532 - loss: 1.2069Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - accuracy: 0.4531 - loss: 1.2068Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 264ms/step - accuracy: 0.4530 - loss: 1.2067Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.4529 - loss: 1.2066Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.4527 - loss: 1.2065Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.4526 - loss: 1.2063Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 264ms/step - accuracy: 0.4525 - loss: 1.2062Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.4524 - loss: 1.2060Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.4524 - loss: 1.2058Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.4523 - loss: 1.2056Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 342ms/step - accuracy: 0.4521 - loss: 1.2053 - val_accuracy: 0.4647 - val_loss: 1.0511\n",
      "Epoch 2/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 259ms/step - accuracy: 0.5000 - loss: 1.0926Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 258ms/step - accuracy: 0.4375 - loss: 1.1692Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 255ms/step - accuracy: 0.4375 - loss: 1.1922Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - accuracy: 0.4375 - loss: 1.2006Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 254ms/step - accuracy: 0.4400 - loss: 1.2000Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 258ms/step - accuracy: 0.4483 - loss: 1.1910Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 257ms/step - accuracy: 0.4506 - loss: 1.1863Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 256ms/step - accuracy: 0.4519 - loss: 1.1869Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 256ms/step - accuracy: 0.4510 - loss: 1.1898Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 256ms/step - accuracy: 0.4484 - loss: 1.1937Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 256ms/step - accuracy: 0.4464 - loss: 1.1977Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 255ms/step - accuracy: 0.4439 - loss: 1.2019Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 256ms/step - accuracy: 0.4427 - loss: 1.2040Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 256ms/step - accuracy: 0.4414 - loss: 1.2055Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 256ms/step - accuracy: 0.4408 - loss: 1.2064Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 256ms/step - accuracy: 0.4401 - loss: 1.2069Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 256ms/step - accuracy: 0.4391 - loss: 1.2076Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 256ms/step - accuracy: 0.4384 - loss: 1.2075Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 256ms/step - accuracy: 0.4379 - loss: 1.2082Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 255ms/step - accuracy: 0.4379 - loss: 1.2081Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 255ms/step - accuracy: 0.4380 - loss: 1.2074Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 256ms/step - accuracy: 0.4381 - loss: 1.2067Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 256ms/step - accuracy: 0.4383 - loss: 1.2056Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 256ms/step - accuracy: 0.4384 - loss: 1.2045Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 256ms/step - accuracy: 0.4382 - loss: 1.2036Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 256ms/step - accuracy: 0.4383 - loss: 1.2024Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 256ms/step - accuracy: 0.4384 - loss: 1.2012Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 256ms/step - accuracy: 0.4383 - loss: 1.2004Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 256ms/step - accuracy: 0.4381 - loss: 1.1997Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 256ms/step - accuracy: 0.4381 - loss: 1.1991Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - accuracy: 0.4379 - loss: 1.1985Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - accuracy: 0.4377 - loss: 1.1983Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - accuracy: 0.4373 - loss: 1.1980Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 256ms/step - accuracy: 0.4369 - loss: 1.1977Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 256ms/step - accuracy: 0.4366 - loss: 1.1974Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 256ms/step - accuracy: 0.4365 - loss: 1.1970Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 256ms/step - accuracy: 0.4362 - loss: 1.1967Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 256ms/step - accuracy: 0.4360 - loss: 1.1963Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 256ms/step - accuracy: 0.4359 - loss: 1.1959Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 256ms/step - accuracy: 0.4358 - loss: 1.1954Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 256ms/step - accuracy: 0.4357 - loss: 1.1950Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 256ms/step - accuracy: 0.4356 - loss: 1.1947Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 255ms/step - accuracy: 0.4357 - loss: 1.1941Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 255ms/step - accuracy: 0.4359 - loss: 1.1934Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 256ms/step - accuracy: 0.4361 - loss: 1.1929Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 255ms/step - accuracy: 0.4362 - loss: 1.1925 Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 255ms/step - accuracy: 0.4364 - loss: 1.1920Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - accuracy: 0.4366 - loss: 1.1915Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - accuracy: 0.4367 - loss: 1.1911Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - accuracy: 0.4368 - loss: 1.1906Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - accuracy: 0.4369 - loss: 1.1902Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - accuracy: 0.4371 - loss: 1.1897Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 256ms/step - accuracy: 0.4371 - loss: 1.1892Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 255ms/step - accuracy: 0.4371 - loss: 1.1888Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 255ms/step - accuracy: 0.4372 - loss: 1.1884Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - accuracy: 0.4372 - loss: 1.1880Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 256ms/step - accuracy: 0.4374 - loss: 1.1875Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.4375 - loss: 1.1870Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.4376 - loss: 1.1866Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.4377 - loss: 1.1862Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 256ms/step - accuracy: 0.4378 - loss: 1.1859Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - accuracy: 0.4378 - loss: 1.1855Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - accuracy: 0.4378 - loss: 1.1853Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 256ms/step - accuracy: 0.4378 - loss: 1.1851Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 257ms/step - accuracy: 0.4378 - loss: 1.1849Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - accuracy: 0.4377 - loss: 1.1847Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - accuracy: 0.4377 - loss: 1.1845Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - accuracy: 0.4377 - loss: 1.1842Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 257ms/step - accuracy: 0.4378 - loss: 1.1839Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - accuracy: 0.4378 - loss: 1.1837Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - accuracy: 0.4378 - loss: 1.1834Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - accuracy: 0.4379 - loss: 1.1831Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 257ms/step - accuracy: 0.4379 - loss: 1.1828Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 257ms/step - accuracy: 0.4380 - loss: 1.1824Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 257ms/step - accuracy: 0.4380 - loss: 1.1821Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 257ms/step - accuracy: 0.4381 - loss: 1.1818Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 257ms/step - accuracy: 0.4381 - loss: 1.1815Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.4382 - loss: 1.1813Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.4382 - loss: 1.1810Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.4383 - loss: 1.1807Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.4384 - loss: 1.1803Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.4385 - loss: 1.1800Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.4386 - loss: 1.1796Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.4387 - loss: 1.1793Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 290ms/step - accuracy: 0.4388 - loss: 1.1786 - val_accuracy: 0.4176 - val_loss: 1.0769\n",
      "Epoch 3/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 267ms/step - accuracy: 0.4375 - loss: 1.0652Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 260ms/step - accuracy: 0.4688 - loss: 1.0378Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 264ms/step - accuracy: 0.4931 - loss: 1.0101Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 262ms/step - accuracy: 0.5065 - loss: 1.0026Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 260ms/step - accuracy: 0.5127 - loss: 0.9977Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 260ms/step - accuracy: 0.5141 - loss: 1.0049Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 260ms/step - accuracy: 0.5146 - loss: 1.0075Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 260ms/step - accuracy: 0.5118 - loss: 1.0128Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 260ms/step - accuracy: 0.5066 - loss: 1.0192Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 260ms/step - accuracy: 0.5047 - loss: 1.0230Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 261ms/step - accuracy: 0.5033 - loss: 1.0266Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 261ms/step - accuracy: 0.5026 - loss: 1.0290Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 261ms/step - accuracy: 0.5012 - loss: 1.0308Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 261ms/step - accuracy: 0.4999 - loss: 1.0321Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 261ms/step - accuracy: 0.4974 - loss: 1.0344Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 261ms/step - accuracy: 0.4954 - loss: 1.0365Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 261ms/step - accuracy: 0.4928 - loss: 1.0393Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 261ms/step - accuracy: 0.4907 - loss: 1.0420Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 262ms/step - accuracy: 0.4895 - loss: 1.0439Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 262ms/step - accuracy: 0.4878 - loss: 1.0459Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 262ms/step - accuracy: 0.4858 - loss: 1.0481Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.4842 - loss: 1.0499Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 261ms/step - accuracy: 0.4830 - loss: 1.0516Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 261ms/step - accuracy: 0.4816 - loss: 1.0533Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 261ms/step - accuracy: 0.4801 - loss: 1.0552Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 261ms/step - accuracy: 0.4790 - loss: 1.0568Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 261ms/step - accuracy: 0.4779 - loss: 1.0583Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 261ms/step - accuracy: 0.4772 - loss: 1.0595Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 262ms/step - accuracy: 0.4768 - loss: 1.0603Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 262ms/step - accuracy: 0.4764 - loss: 1.0611Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 262ms/step - accuracy: 0.4759 - loss: 1.0619Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - accuracy: 0.4753 - loss: 1.0629Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - accuracy: 0.4748 - loss: 1.0638Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 262ms/step - accuracy: 0.4743 - loss: 1.0649Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 261ms/step - accuracy: 0.4736 - loss: 1.0661Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 261ms/step - accuracy: 0.4731 - loss: 1.0671Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 261ms/step - accuracy: 0.4724 - loss: 1.0682Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 262ms/step - accuracy: 0.4719 - loss: 1.0691Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 262ms/step - accuracy: 0.4715 - loss: 1.0701Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 262ms/step - accuracy: 0.4710 - loss: 1.0711Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 262ms/step - accuracy: 0.4706 - loss: 1.0721Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 262ms/step - accuracy: 0.4703 - loss: 1.0729Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 262ms/step - accuracy: 0.4699 - loss: 1.0737Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 262ms/step - accuracy: 0.4696 - loss: 1.0744Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 262ms/step - accuracy: 0.4693 - loss: 1.0750Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 262ms/step - accuracy: 0.4691 - loss: 1.0754Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 262ms/step - accuracy: 0.4689 - loss: 1.0759 Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 262ms/step - accuracy: 0.4688 - loss: 1.0763Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 262ms/step - accuracy: 0.4686 - loss: 1.0766Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 262ms/step - accuracy: 0.4686 - loss: 1.0769Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.4685 - loss: 1.0773Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.4684 - loss: 1.0777Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.4683 - loss: 1.0782Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - accuracy: 0.4681 - loss: 1.0786Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 262ms/step - accuracy: 0.4680 - loss: 1.0791Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - accuracy: 0.4679 - loss: 1.0796Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - accuracy: 0.4677 - loss: 1.0802Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 263ms/step - accuracy: 0.4675 - loss: 1.0808Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.4673 - loss: 1.0815Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.4672 - loss: 1.0820Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.4670 - loss: 1.0827Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 263ms/step - accuracy: 0.4669 - loss: 1.0832Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 263ms/step - accuracy: 0.4667 - loss: 1.0838Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 263ms/step - accuracy: 0.4666 - loss: 1.0843Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 263ms/step - accuracy: 0.4665 - loss: 1.0848Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.4664 - loss: 1.0852Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.4664 - loss: 1.0856Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.4663 - loss: 1.0860Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.4663 - loss: 1.0863Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 263ms/step - accuracy: 0.4663 - loss: 1.0867Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 263ms/step - accuracy: 0.4662 - loss: 1.0871Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 263ms/step - accuracy: 0.4662 - loss: 1.0874Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 263ms/step - accuracy: 0.4662 - loss: 1.0878Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 263ms/step - accuracy: 0.4662 - loss: 1.0881Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 263ms/step - accuracy: 0.4661 - loss: 1.0884Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 263ms/step - accuracy: 0.4661 - loss: 1.0887Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 263ms/step - accuracy: 0.4660 - loss: 1.0891Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.4659 - loss: 1.0894Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.4658 - loss: 1.0896Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.4658 - loss: 1.0899Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.4657 - loss: 1.0902Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.4656 - loss: 1.0904Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.4655 - loss: 1.0907Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.4654 - loss: 1.0910Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 295ms/step - accuracy: 0.4652 - loss: 1.0914 - val_accuracy: 0.4824 - val_loss: 0.9777\n",
      "Epoch 4/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 272ms/step - accuracy: 0.5625 - loss: 1.0597Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 260ms/step - accuracy: 0.5000 - loss: 1.0968Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 282ms/step - accuracy: 0.4792 - loss: 1.1334Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 290ms/step - accuracy: 0.4648 - loss: 1.1541Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 289ms/step - accuracy: 0.4519 - loss: 1.1651Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 285ms/step - accuracy: 0.4460 - loss: 1.1615Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 287ms/step - accuracy: 0.4410 - loss: 1.1567Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 288ms/step - accuracy: 0.4376 - loss: 1.1533Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 288ms/step - accuracy: 0.4384 - loss: 1.1467Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 288ms/step - accuracy: 0.4383 - loss: 1.1437Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 288ms/step - accuracy: 0.4367 - loss: 1.1447Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 288ms/step - accuracy: 0.4350 - loss: 1.1446Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 288ms/step - accuracy: 0.4341 - loss: 1.1449Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 287ms/step - accuracy: 0.4334 - loss: 1.1452Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 288ms/step - accuracy: 0.4334 - loss: 1.1443Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 287ms/step - accuracy: 0.4331 - loss: 1.1441Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 287ms/step - accuracy: 0.4330 - loss: 1.1436Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 288ms/step - accuracy: 0.4326 - loss: 1.1437Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.4320 - loss: 1.1438Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.4318 - loss: 1.1439Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.4318 - loss: 1.1440Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 287ms/step - accuracy: 0.4322 - loss: 1.1434Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 287ms/step - accuracy: 0.4322 - loss: 1.1434Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 287ms/step - accuracy: 0.4321 - loss: 1.1434Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 287ms/step - accuracy: 0.4319 - loss: 1.1435Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 287ms/step - accuracy: 0.4318 - loss: 1.1435Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 287ms/step - accuracy: 0.4318 - loss: 1.1434Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 288ms/step - accuracy: 0.4318 - loss: 1.1433Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 288ms/step - accuracy: 0.4317 - loss: 1.1432Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 288ms/step - accuracy: 0.4315 - loss: 1.1430Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 289ms/step - accuracy: 0.4312 - loss: 1.1432Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 288ms/step - accuracy: 0.4308 - loss: 1.1436Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 289ms/step - accuracy: 0.4306 - loss: 1.1437Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.4305 - loss: 1.1438Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.4304 - loss: 1.1438Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.4305 - loss: 1.1437Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.4306 - loss: 1.1434Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.4308 - loss: 1.1431Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.4309 - loss: 1.1428Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4310 - loss: 1.1427Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4313 - loss: 1.1423Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4316 - loss: 1.1419Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4319 - loss: 1.1414Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 288ms/step - accuracy: 0.4322 - loss: 1.1409Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 289ms/step - accuracy: 0.4326 - loss: 1.1403Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 289ms/step - accuracy: 0.4330 - loss: 1.1396Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.4334 - loss: 1.1390Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.4337 - loss: 1.1385Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.4339 - loss: 1.1380Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 289ms/step - accuracy: 0.4341 - loss: 1.1374Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 289ms/step - accuracy: 0.4342 - loss: 1.1369 Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 290ms/step - accuracy: 0.4344 - loss: 1.1365Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 290ms/step - accuracy: 0.4346 - loss: 1.1360Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 290ms/step - accuracy: 0.4347 - loss: 1.1356Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 290ms/step - accuracy: 0.4349 - loss: 1.1351Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 291ms/step - accuracy: 0.4350 - loss: 1.1347Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 291ms/step - accuracy: 0.4352 - loss: 1.1342Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - accuracy: 0.4354 - loss: 1.1336Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - accuracy: 0.4356 - loss: 1.1333Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 291ms/step - accuracy: 0.4357 - loss: 1.1328Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.4359 - loss: 1.1324Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.4361 - loss: 1.1319Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.4362 - loss: 1.1316Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.4364 - loss: 1.1313Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - accuracy: 0.4365 - loss: 1.1310Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - accuracy: 0.4366 - loss: 1.1308Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - accuracy: 0.4366 - loss: 1.1306Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - accuracy: 0.4367 - loss: 1.1303Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - accuracy: 0.4368 - loss: 1.1301Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - accuracy: 0.4368 - loss: 1.1298Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 294ms/step - accuracy: 0.4369 - loss: 1.1296Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 294ms/step - accuracy: 0.4369 - loss: 1.1293Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 293ms/step - accuracy: 0.4370 - loss: 1.1290Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 293ms/step - accuracy: 0.4371 - loss: 1.1287Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 0.4372 - loss: 1.1284Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 0.4373 - loss: 1.1282Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 293ms/step - accuracy: 0.4374 - loss: 1.1280Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 294ms/step - accuracy: 0.4375 - loss: 1.1277Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - accuracy: 0.4376 - loss: 1.1275Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 293ms/step - accuracy: 0.4376 - loss: 1.1273Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 294ms/step - accuracy: 0.4378 - loss: 1.1270Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.4379 - loss: 1.1268Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 0.4380 - loss: 1.1265Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.4381 - loss: 1.1263Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 328ms/step - accuracy: 0.4383 - loss: 1.1260 - val_accuracy: 0.5588 - val_loss: 0.9148\n",
      "Epoch 5/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 284ms/step - accuracy: 0.3750 - loss: 1.0509Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 284ms/step - accuracy: 0.3438 - loss: 1.1551Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 282ms/step - accuracy: 0.3611 - loss: 1.1467Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 286ms/step - accuracy: 0.3763 - loss: 1.1362Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 287ms/step - accuracy: 0.3860 - loss: 1.1205Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 287ms/step - accuracy: 0.3911 - loss: 1.1121Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 288ms/step - accuracy: 0.3939 - loss: 1.1076Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 288ms/step - accuracy: 0.3955 - loss: 1.1064Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 289ms/step - accuracy: 0.3978 - loss: 1.1050Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 289ms/step - accuracy: 0.3999 - loss: 1.1035Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 287ms/step - accuracy: 0.4028 - loss: 1.1014Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 287ms/step - accuracy: 0.4066 - loss: 1.0987Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 287ms/step - accuracy: 0.4101 - loss: 1.0963Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 287ms/step - accuracy: 0.4130 - loss: 1.0940Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 287ms/step - accuracy: 0.4160 - loss: 1.0933Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 0.4191 - loss: 1.0927Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 0.4221 - loss: 1.0913Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 290ms/step - accuracy: 0.4253 - loss: 1.0898Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 289ms/step - accuracy: 0.4278 - loss: 1.0895Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 289ms/step - accuracy: 0.4299 - loss: 1.0898Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 289ms/step - accuracy: 0.4316 - loss: 1.0897Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 288ms/step - accuracy: 0.4333 - loss: 1.0895Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 288ms/step - accuracy: 0.4347 - loss: 1.0899Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 287ms/step - accuracy: 0.4358 - loss: 1.0906Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 288ms/step - accuracy: 0.4369 - loss: 1.0912Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 288ms/step - accuracy: 0.4378 - loss: 1.0916Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 289ms/step - accuracy: 0.4388 - loss: 1.0917Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 288ms/step - accuracy: 0.4400 - loss: 1.0914Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 288ms/step - accuracy: 0.4411 - loss: 1.0911Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 288ms/step - accuracy: 0.4421 - loss: 1.0910Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 288ms/step - accuracy: 0.4431 - loss: 1.0906Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 288ms/step - accuracy: 0.4441 - loss: 1.0901Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.4453 - loss: 1.0894Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.4462 - loss: 1.0890Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.4470 - loss: 1.0887Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 288ms/step - accuracy: 0.4478 - loss: 1.0883Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.4485 - loss: 1.0881Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.4493 - loss: 1.0877Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.4499 - loss: 1.0874Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4505 - loss: 1.0873Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4510 - loss: 1.0871Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4515 - loss: 1.0869Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4518 - loss: 1.0868Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 289ms/step - accuracy: 0.4521 - loss: 1.0867Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 289ms/step - accuracy: 0.4522 - loss: 1.0869Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 288ms/step - accuracy: 0.4524 - loss: 1.0870Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.4525 - loss: 1.0872Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.4527 - loss: 1.0874Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.4527 - loss: 1.0876Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.4527 - loss: 1.0878Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 288ms/step - accuracy: 0.4528 - loss: 1.0880 Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 288ms/step - accuracy: 0.4528 - loss: 1.0881Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 288ms/step - accuracy: 0.4529 - loss: 1.0881Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - accuracy: 0.4530 - loss: 1.0880Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - accuracy: 0.4530 - loss: 1.0879Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - accuracy: 0.4531 - loss: 1.0878Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - accuracy: 0.4532 - loss: 1.0877Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.4533 - loss: 1.0876Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.4534 - loss: 1.0874Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 288ms/step - accuracy: 0.4534 - loss: 1.0874Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 288ms/step - accuracy: 0.4534 - loss: 1.0874Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 289ms/step - accuracy: 0.4534 - loss: 1.0873Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 289ms/step - accuracy: 0.4534 - loss: 1.0873Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 289ms/step - accuracy: 0.4533 - loss: 1.0873Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.4533 - loss: 1.0873Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.4533 - loss: 1.0873Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.4532 - loss: 1.0873Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 288ms/step - accuracy: 0.4532 - loss: 1.0873Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 288ms/step - accuracy: 0.4532 - loss: 1.0873Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 288ms/step - accuracy: 0.4531 - loss: 1.0873Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 288ms/step - accuracy: 0.4530 - loss: 1.0874Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 288ms/step - accuracy: 0.4530 - loss: 1.0874Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 288ms/step - accuracy: 0.4529 - loss: 1.0875Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 288ms/step - accuracy: 0.4529 - loss: 1.0874Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 288ms/step - accuracy: 0.4529 - loss: 1.0874Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 288ms/step - accuracy: 0.4529 - loss: 1.0874Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 288ms/step - accuracy: 0.4529 - loss: 1.0874Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 289ms/step - accuracy: 0.4530 - loss: 1.0874Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - accuracy: 0.4530 - loss: 1.0873Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 289ms/step - accuracy: 0.4530 - loss: 1.0873Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 288ms/step - accuracy: 0.4530 - loss: 1.0873Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.4531 - loss: 1.0872Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.4531 - loss: 1.0871Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.4531 - loss: 1.0871Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 322ms/step - accuracy: 0.4531 - loss: 1.0870 - val_accuracy: 0.4824 - val_loss: 1.0294\n",
      "Epoch 6/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 312ms/step - accuracy: 0.6250 - loss: 0.8780Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 288ms/step - accuracy: 0.5469 - loss: 0.9186Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 281ms/step - accuracy: 0.5243 - loss: 0.9435Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 281ms/step - accuracy: 0.5104 - loss: 0.9535Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 281ms/step - accuracy: 0.5033 - loss: 0.9684Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 281ms/step - accuracy: 0.4941 - loss: 0.9880Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 282ms/step - accuracy: 0.4886 - loss: 1.0004Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 283ms/step - accuracy: 0.4841 - loss: 1.0130Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 285ms/step - accuracy: 0.4813 - loss: 1.0208Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 285ms/step - accuracy: 0.4794 - loss: 1.0273Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 285ms/step - accuracy: 0.4782 - loss: 1.0326Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 285ms/step - accuracy: 0.4774 - loss: 1.0355Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 286ms/step - accuracy: 0.4769 - loss: 1.0380Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 286ms/step - accuracy: 0.4760 - loss: 1.0400Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 287ms/step - accuracy: 0.4759 - loss: 1.0412Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 287ms/step - accuracy: 0.4755 - loss: 1.0423Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 288ms/step - accuracy: 0.4752 - loss: 1.0433Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 290ms/step - accuracy: 0.4743 - loss: 1.0445Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 290ms/step - accuracy: 0.4732 - loss: 1.0455Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 290ms/step - accuracy: 0.4720 - loss: 1.0470Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 290ms/step - accuracy: 0.4710 - loss: 1.0483Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 290ms/step - accuracy: 0.4698 - loss: 1.0499Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 290ms/step - accuracy: 0.4687 - loss: 1.0515Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 290ms/step - accuracy: 0.4675 - loss: 1.0530Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 290ms/step - accuracy: 0.4664 - loss: 1.0543Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 290ms/step - accuracy: 0.4654 - loss: 1.0556Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - accuracy: 0.4647 - loss: 1.0568Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - accuracy: 0.4642 - loss: 1.0577Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - accuracy: 0.4635 - loss: 1.0587Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - accuracy: 0.4630 - loss: 1.0596Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - accuracy: 0.4625 - loss: 1.0605Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - accuracy: 0.4622 - loss: 1.0612Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - accuracy: 0.4619 - loss: 1.0619Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 290ms/step - accuracy: 0.4616 - loss: 1.0626Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 289ms/step - accuracy: 0.4613 - loss: 1.0633Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 289ms/step - accuracy: 0.4608 - loss: 1.0639Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.4605 - loss: 1.0645Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.4601 - loss: 1.0650Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 288ms/step - accuracy: 0.4598 - loss: 1.0656Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4595 - loss: 1.0661Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4593 - loss: 1.0664Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4591 - loss: 1.0667Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 288ms/step - accuracy: 0.4590 - loss: 1.0668Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 288ms/step - accuracy: 0.4590 - loss: 1.0669Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 288ms/step - accuracy: 0.4589 - loss: 1.0670Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 288ms/step - accuracy: 0.4589 - loss: 1.0670Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.4589 - loss: 1.0670Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.4589 - loss: 1.0671Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.4588 - loss: 1.0672Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 287ms/step - accuracy: 0.4587 - loss: 1.0672Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 287ms/step - accuracy: 0.4586 - loss: 1.0672 Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 288ms/step - accuracy: 0.4586 - loss: 1.0671Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 288ms/step - accuracy: 0.4585 - loss: 1.0671Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.4584 - loss: 1.0671Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.4583 - loss: 1.0669Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.4583 - loss: 1.0668Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - accuracy: 0.4582 - loss: 1.0667Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.4582 - loss: 1.0665Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.4583 - loss: 1.0663Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 287ms/step - accuracy: 0.4584 - loss: 1.0661Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - accuracy: 0.4584 - loss: 1.0660Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - accuracy: 0.4585 - loss: 1.0658Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - accuracy: 0.4586 - loss: 1.0656Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 287ms/step - accuracy: 0.4587 - loss: 1.0654Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.4588 - loss: 1.0652Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.4589 - loss: 1.0650Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.4590 - loss: 1.0648Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - accuracy: 0.4591 - loss: 1.0645Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - accuracy: 0.4591 - loss: 1.0643Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - accuracy: 0.4592 - loss: 1.0641Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 286ms/step - accuracy: 0.4592 - loss: 1.0640Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 287ms/step - accuracy: 0.4592 - loss: 1.0639Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 287ms/step - accuracy: 0.4593 - loss: 1.0638Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 287ms/step - accuracy: 0.4593 - loss: 1.0637Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 287ms/step - accuracy: 0.4594 - loss: 1.0635Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 287ms/step - accuracy: 0.4594 - loss: 1.0634Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 286ms/step - accuracy: 0.4595 - loss: 1.0632Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 286ms/step - accuracy: 0.4595 - loss: 1.0631Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - accuracy: 0.4596 - loss: 1.0629Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - accuracy: 0.4596 - loss: 1.0628Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 286ms/step - accuracy: 0.4597 - loss: 1.0626Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.4597 - loss: 1.0625Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.4598 - loss: 1.0625Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.4599 - loss: 1.0624Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 319ms/step - accuracy: 0.4601 - loss: 1.0622 - val_accuracy: 0.4412 - val_loss: 0.9653\n",
      "Epoch 7/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 286ms/step - accuracy: 0.7500 - loss: 0.6954Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 282ms/step - accuracy: 0.7031 - loss: 0.8077Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 291ms/step - accuracy: 0.6493 - loss: 0.9204Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 287ms/step - accuracy: 0.6198 - loss: 0.9599Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 288ms/step - accuracy: 0.5983 - loss: 0.9872Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 286ms/step - accuracy: 0.5802 - loss: 1.0103Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 287ms/step - accuracy: 0.5726 - loss: 1.0176Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 296ms/step - accuracy: 0.5664 - loss: 1.0225Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 296ms/step - accuracy: 0.5591 - loss: 1.0287Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 295ms/step - accuracy: 0.5506 - loss: 1.0362Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 293ms/step - accuracy: 0.5445 - loss: 1.0415Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 293ms/step - accuracy: 0.5386 - loss: 1.0455Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 295ms/step - accuracy: 0.5342 - loss: 1.0488Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 294ms/step - accuracy: 0.5308 - loss: 1.0509Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 293ms/step - accuracy: 0.5279 - loss: 1.0523Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 292ms/step - accuracy: 0.5257 - loss: 1.0529Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 292ms/step - accuracy: 0.5228 - loss: 1.0540Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 0.5212 - loss: 1.0543Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 0.5197 - loss: 1.0541Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 0.5187 - loss: 1.0533Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 293ms/step - accuracy: 0.5180 - loss: 1.0524Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 292ms/step - accuracy: 0.5172 - loss: 1.0517Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 292ms/step - accuracy: 0.5161 - loss: 1.0512Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 292ms/step - accuracy: 0.5150 - loss: 1.0516Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 292ms/step - accuracy: 0.5141 - loss: 1.0516Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 292ms/step - accuracy: 0.5130 - loss: 1.0522Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 292ms/step - accuracy: 0.5117 - loss: 1.0526Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 293ms/step - accuracy: 0.5106 - loss: 1.0530Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 293ms/step - accuracy: 0.5093 - loss: 1.0536Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 293ms/step - accuracy: 0.5081 - loss: 1.0539Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 292ms/step - accuracy: 0.5067 - loss: 1.0545Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 292ms/step - accuracy: 0.5053 - loss: 1.0549Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 292ms/step - accuracy: 0.5039 - loss: 1.0552Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 292ms/step - accuracy: 0.5028 - loss: 1.0554Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 292ms/step - accuracy: 0.5017 - loss: 1.0558Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 292ms/step - accuracy: 0.5006 - loss: 1.0559Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 292ms/step - accuracy: 0.4996 - loss: 1.0560Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 293ms/step - accuracy: 0.4986 - loss: 1.0562Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 293ms/step - accuracy: 0.4978 - loss: 1.0563Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 293ms/step - accuracy: 0.4969 - loss: 1.0565Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 292ms/step - accuracy: 0.4961 - loss: 1.0566Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 293ms/step - accuracy: 0.4954 - loss: 1.0565Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 292ms/step - accuracy: 0.4946 - loss: 1.0565Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 292ms/step - accuracy: 0.4940 - loss: 1.0564Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 292ms/step - accuracy: 0.4934 - loss: 1.0563Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 292ms/step - accuracy: 0.4928 - loss: 1.0562Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 292ms/step - accuracy: 0.4922 - loss: 1.0561Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.4916 - loss: 1.0562Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.4909 - loss: 1.0561Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.4903 - loss: 1.0561Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 292ms/step - accuracy: 0.4897 - loss: 1.0561 Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 292ms/step - accuracy: 0.4890 - loss: 1.0562Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 292ms/step - accuracy: 0.4884 - loss: 1.0562Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 292ms/step - accuracy: 0.4879 - loss: 1.0562Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 292ms/step - accuracy: 0.4874 - loss: 1.0561Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 292ms/step - accuracy: 0.4870 - loss: 1.0561Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 292ms/step - accuracy: 0.4865 - loss: 1.0562Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.4860 - loss: 1.0563Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 293ms/step - accuracy: 0.4856 - loss: 1.0564Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.4851 - loss: 1.0565Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 292ms/step - accuracy: 0.4847 - loss: 1.0566Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.4843 - loss: 1.0566Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.4840 - loss: 1.0566Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 292ms/step - accuracy: 0.4836 - loss: 1.0566Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.4832 - loss: 1.0566Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.4829 - loss: 1.0566Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.4825 - loss: 1.0566Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - accuracy: 0.4822 - loss: 1.0567Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - accuracy: 0.4819 - loss: 1.0567Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - accuracy: 0.4817 - loss: 1.0567Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 292ms/step - accuracy: 0.4814 - loss: 1.0568Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 292ms/step - accuracy: 0.4812 - loss: 1.0567Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 292ms/step - accuracy: 0.4809 - loss: 1.0567Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 292ms/step - accuracy: 0.4807 - loss: 1.0567Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 292ms/step - accuracy: 0.4805 - loss: 1.0567Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 292ms/step - accuracy: 0.4802 - loss: 1.0567Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 292ms/step - accuracy: 0.4799 - loss: 1.0567Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 292ms/step - accuracy: 0.4797 - loss: 1.0568Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - accuracy: 0.4795 - loss: 1.0568Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - accuracy: 0.4793 - loss: 1.0568Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 292ms/step - accuracy: 0.4791 - loss: 1.0567Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.4790 - loss: 1.0567Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.4788 - loss: 1.0566Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 0.4787 - loss: 1.0566Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 325ms/step - accuracy: 0.4784 - loss: 1.0565 - val_accuracy: 0.4824 - val_loss: 0.9077\n",
      "Epoch 8/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 281ms/step - accuracy: 0.5000 - loss: 1.0827Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 271ms/step - accuracy: 0.4531 - loss: 1.1398Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 288ms/step - accuracy: 0.4340 - loss: 1.1472Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 288ms/step - accuracy: 0.4310 - loss: 1.1302Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 289ms/step - accuracy: 0.4223 - loss: 1.1316Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 288ms/step - accuracy: 0.4196 - loss: 1.1289Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 286ms/step - accuracy: 0.4183 - loss: 1.1236Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 287ms/step - accuracy: 0.4207 - loss: 1.1144Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 287ms/step - accuracy: 0.4226 - loss: 1.1072Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 288ms/step - accuracy: 0.4260 - loss: 1.0998Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 287ms/step - accuracy: 0.4275 - loss: 1.0953Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 286ms/step - accuracy: 0.4297 - loss: 1.0923Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 286ms/step - accuracy: 0.4332 - loss: 1.0878Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 286ms/step - accuracy: 0.4351 - loss: 1.0857Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 0.4370 - loss: 1.0844Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 0.4382 - loss: 1.0832Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 286ms/step - accuracy: 0.4392 - loss: 1.0818Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 287ms/step - accuracy: 0.4401 - loss: 1.0806Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 290ms/step - accuracy: 0.4401 - loss: 1.0800Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 291ms/step - accuracy: 0.4400 - loss: 1.0796Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 291ms/step - accuracy: 0.4399 - loss: 1.0794Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 292ms/step - accuracy: 0.4402 - loss: 1.0790Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 293ms/step - accuracy: 0.4403 - loss: 1.0787Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 293ms/step - accuracy: 0.4405 - loss: 1.0782Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 294ms/step - accuracy: 0.4408 - loss: 1.0781Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 294ms/step - accuracy: 0.4408 - loss: 1.0780Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 295ms/step - accuracy: 0.4410 - loss: 1.0778Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 296ms/step - accuracy: 0.4411 - loss: 1.0775Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 296ms/step - accuracy: 0.4413 - loss: 1.0774Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 297ms/step - accuracy: 0.4415 - loss: 1.0771Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 298ms/step - accuracy: 0.4417 - loss: 1.0769Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 299ms/step - accuracy: 0.4420 - loss: 1.0768Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 299ms/step - accuracy: 0.4422 - loss: 1.0766Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.4425 - loss: 1.0764Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.4430 - loss: 1.0761Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 301ms/step - accuracy: 0.4433 - loss: 1.0760Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 301ms/step - accuracy: 0.4437 - loss: 1.0758Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 301ms/step - accuracy: 0.4442 - loss: 1.0755Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 302ms/step - accuracy: 0.4445 - loss: 1.0753Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 302ms/step - accuracy: 0.4448 - loss: 1.0753Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 302ms/step - accuracy: 0.4450 - loss: 1.0753Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 302ms/step - accuracy: 0.4454 - loss: 1.0751Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 302ms/step - accuracy: 0.4458 - loss: 1.0749Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 302ms/step - accuracy: 0.4461 - loss: 1.0748Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 302ms/step - accuracy: 0.4465 - loss: 1.0747Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 302ms/step - accuracy: 0.4468 - loss: 1.0746Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.4472 - loss: 1.0744Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.4475 - loss: 1.0741Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 303ms/step - accuracy: 0.4478 - loss: 1.0740Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 303ms/step - accuracy: 0.4481 - loss: 1.0737Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 303ms/step - accuracy: 0.4484 - loss: 1.0735Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 303ms/step - accuracy: 0.4486 - loss: 1.0732Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 303ms/step - accuracy: 0.4487 - loss: 1.0730 Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 303ms/step - accuracy: 0.4489 - loss: 1.0728Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 303ms/step - accuracy: 0.4491 - loss: 1.0726Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.4492 - loss: 1.0724Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.4493 - loss: 1.0722Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.4495 - loss: 1.0720Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.4496 - loss: 1.0719Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.4497 - loss: 1.0718Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.4499 - loss: 1.0717Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.4501 - loss: 1.0716Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.4502 - loss: 1.0715Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.4503 - loss: 1.0713Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.4504 - loss: 1.0712Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.4505 - loss: 1.0711Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.4506 - loss: 1.0709Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.4507 - loss: 1.0707Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 305ms/step - accuracy: 0.4508 - loss: 1.0706Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 305ms/step - accuracy: 0.4509 - loss: 1.0704Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 305ms/step - accuracy: 0.4510 - loss: 1.0702Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - accuracy: 0.4511 - loss: 1.0700Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - accuracy: 0.4511 - loss: 1.0699Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - accuracy: 0.4512 - loss: 1.0697Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - accuracy: 0.4512 - loss: 1.0695Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - accuracy: 0.4513 - loss: 1.0693Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - accuracy: 0.4514 - loss: 1.0690Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - accuracy: 0.4515 - loss: 1.0688Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 305ms/step - accuracy: 0.4516 - loss: 1.0686Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.4517 - loss: 1.0684Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.4518 - loss: 1.0682Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.4519 - loss: 1.0680Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.4520 - loss: 1.0678Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.4522 - loss: 1.0676Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 341ms/step - accuracy: 0.4525 - loss: 1.0670 - val_accuracy: 0.4353 - val_loss: 0.9849\n",
      "Epoch 9/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 307ms/step - accuracy: 0.5000 - loss: 0.9149Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 312ms/step - accuracy: 0.5000 - loss: 0.9341Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 317ms/step - accuracy: 0.4792 - loss: 0.9511Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 316ms/step - accuracy: 0.4688 - loss: 0.9668Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 315ms/step - accuracy: 0.4725 - loss: 0.9789Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 312ms/step - accuracy: 0.4788 - loss: 0.9860Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 312ms/step - accuracy: 0.4869 - loss: 0.9872Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 311ms/step - accuracy: 0.4935 - loss: 0.9858Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 312ms/step - accuracy: 0.4996 - loss: 0.9828Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 314ms/step - accuracy: 0.5034 - loss: 0.9798Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 313ms/step - accuracy: 0.5051 - loss: 0.9798Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 314ms/step - accuracy: 0.5069 - loss: 0.9798Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 315ms/step - accuracy: 0.5086 - loss: 0.9792Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 313ms/step - accuracy: 0.5099 - loss: 0.9779Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 313ms/step - accuracy: 0.5103 - loss: 0.9772Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 313ms/step - accuracy: 0.5109 - loss: 0.9764Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 313ms/step - accuracy: 0.5107 - loss: 0.9768Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 312ms/step - accuracy: 0.5101 - loss: 0.9785Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 312ms/step - accuracy: 0.5092 - loss: 0.9801Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 312ms/step - accuracy: 0.5080 - loss: 0.9817Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - accuracy: 0.5066 - loss: 0.9837Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 313ms/step - accuracy: 0.5055 - loss: 0.9854Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 313ms/step - accuracy: 0.5041 - loss: 0.9874Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 313ms/step - accuracy: 0.5029 - loss: 0.9892Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 313ms/step - accuracy: 0.5016 - loss: 0.9909Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 313ms/step - accuracy: 0.5004 - loss: 0.9926Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 313ms/step - accuracy: 0.4990 - loss: 0.9944Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 312ms/step - accuracy: 0.4975 - loss: 0.9963Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 312ms/step - accuracy: 0.4962 - loss: 0.9979Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 311ms/step - accuracy: 0.4951 - loss: 0.9992Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 311ms/step - accuracy: 0.4939 - loss: 1.0005Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - accuracy: 0.4928 - loss: 1.0016Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - accuracy: 0.4918 - loss: 1.0026Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.4910 - loss: 1.0035Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.4902 - loss: 1.0042Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.4896 - loss: 1.0046Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 312ms/step - accuracy: 0.4891 - loss: 1.0051Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 312ms/step - accuracy: 0.4885 - loss: 1.0054Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 312ms/step - accuracy: 0.4879 - loss: 1.0059Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 312ms/step - accuracy: 0.4873 - loss: 1.0062Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.4868 - loss: 1.0066Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.4862 - loss: 1.0071Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.4856 - loss: 1.0076Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - accuracy: 0.4849 - loss: 1.0081Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - accuracy: 0.4842 - loss: 1.0087Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - accuracy: 0.4836 - loss: 1.0093Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.4829 - loss: 1.0099Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.4823 - loss: 1.0104Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.4818 - loss: 1.0108Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.4813 - loss: 1.0111Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.4809 - loss: 1.0115Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.4806 - loss: 1.0117Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 312ms/step - accuracy: 0.4804 - loss: 1.0120 Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 312ms/step - accuracy: 0.4802 - loss: 1.0122Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 312ms/step - accuracy: 0.4799 - loss: 1.0125Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 312ms/step - accuracy: 0.4797 - loss: 1.0128Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 312ms/step - accuracy: 0.4795 - loss: 1.0131Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 312ms/step - accuracy: 0.4792 - loss: 1.0134Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 312ms/step - accuracy: 0.4790 - loss: 1.0137Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.4788 - loss: 1.0140Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.4784 - loss: 1.0143Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.4781 - loss: 1.0148Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 312ms/step - accuracy: 0.4778 - loss: 1.0152Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 312ms/step - accuracy: 0.4775 - loss: 1.0156Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 312ms/step - accuracy: 0.4771 - loss: 1.0160Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.4768 - loss: 1.0164Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.4765 - loss: 1.0168Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.4762 - loss: 1.0173Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 313ms/step - accuracy: 0.4759 - loss: 1.0177Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 313ms/step - accuracy: 0.4756 - loss: 1.0181Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 313ms/step - accuracy: 0.4753 - loss: 1.0186Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 313ms/step - accuracy: 0.4750 - loss: 1.0190Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 313ms/step - accuracy: 0.4747 - loss: 1.0194Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 313ms/step - accuracy: 0.4745 - loss: 1.0199Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 313ms/step - accuracy: 0.4742 - loss: 1.0203Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.4740 - loss: 1.0207Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.4738 - loss: 1.0211Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.4736 - loss: 1.0215Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - accuracy: 0.4733 - loss: 1.0219Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - accuracy: 0.4730 - loss: 1.0223Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - accuracy: 0.4728 - loss: 1.0227Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4726 - loss: 1.0230Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4724 - loss: 1.0234Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4721 - loss: 1.0237Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 349ms/step - accuracy: 0.4717 - loss: 1.0243 - val_accuracy: 0.4412 - val_loss: 0.9769\n",
      "Epoch 10/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 305ms/step - accuracy: 0.6250 - loss: 0.9088Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 300ms/step - accuracy: 0.6250 - loss: 0.8909Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 326ms/step - accuracy: 0.6319 - loss: 0.8675Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 322ms/step - accuracy: 0.6146 - loss: 0.8698Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 321ms/step - accuracy: 0.6092 - loss: 0.8682Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 317ms/step - accuracy: 0.6066 - loss: 0.8666Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 315ms/step - accuracy: 0.6054 - loss: 0.8643Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 318ms/step - accuracy: 0.6000 - loss: 0.8684Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 318ms/step - accuracy: 0.5943 - loss: 0.8714Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 317ms/step - accuracy: 0.5886 - loss: 0.8762Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 317ms/step - accuracy: 0.5852 - loss: 0.8795Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 315ms/step - accuracy: 0.5820 - loss: 0.8827Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 316ms/step - accuracy: 0.5787 - loss: 0.8876Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 316ms/step - accuracy: 0.5763 - loss: 0.8909Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 316ms/step - accuracy: 0.5734 - loss: 0.8954Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 315ms/step - accuracy: 0.5700 - loss: 0.9004Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.5674 - loss: 0.9045Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 0.5652 - loss: 0.9083Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 316ms/step - accuracy: 0.5625 - loss: 0.9124Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 316ms/step - accuracy: 0.5590 - loss: 0.9172Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 315ms/step - accuracy: 0.5557 - loss: 0.9216Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 315ms/step - accuracy: 0.5526 - loss: 0.9255Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 314ms/step - accuracy: 0.5495 - loss: 0.9291Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 314ms/step - accuracy: 0.5465 - loss: 0.9325Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 314ms/step - accuracy: 0.5432 - loss: 0.9360Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 315ms/step - accuracy: 0.5402 - loss: 0.9391Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 315ms/step - accuracy: 0.5372 - loss: 0.9424Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 315ms/step - accuracy: 0.5346 - loss: 0.9454Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 315ms/step - accuracy: 0.5322 - loss: 0.9482Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 315ms/step - accuracy: 0.5303 - loss: 0.9505Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 315ms/step - accuracy: 0.5284 - loss: 0.9528Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - accuracy: 0.5266 - loss: 0.9550Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - accuracy: 0.5248 - loss: 0.9571Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 314ms/step - accuracy: 0.5232 - loss: 0.9591Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 314ms/step - accuracy: 0.5215 - loss: 0.9612Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 314ms/step - accuracy: 0.5199 - loss: 0.9630Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 315ms/step - accuracy: 0.5185 - loss: 0.9647Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 315ms/step - accuracy: 0.5172 - loss: 0.9665Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 315ms/step - accuracy: 0.5160 - loss: 0.9682Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 315ms/step - accuracy: 0.5147 - loss: 0.9698Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 314ms/step - accuracy: 0.5135 - loss: 0.9714Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 314ms/step - accuracy: 0.5123 - loss: 0.9728Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 314ms/step - accuracy: 0.5112 - loss: 0.9742Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 314ms/step - accuracy: 0.5102 - loss: 0.9754Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 314ms/step - accuracy: 0.5093 - loss: 0.9764Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 314ms/step - accuracy: 0.5085 - loss: 0.9773Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 315ms/step - accuracy: 0.5078 - loss: 0.9781Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 314ms/step - accuracy: 0.5071 - loss: 0.9789Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 314ms/step - accuracy: 0.5064 - loss: 0.9796Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.5058 - loss: 0.9804Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.5052 - loss: 0.9811Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.5046 - loss: 0.9818Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 314ms/step - accuracy: 0.5041 - loss: 0.9825Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 314ms/step - accuracy: 0.5035 - loss: 0.9832 Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 314ms/step - accuracy: 0.5029 - loss: 0.9839Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 314ms/step - accuracy: 0.5024 - loss: 0.9845Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 314ms/step - accuracy: 0.5019 - loss: 0.9850Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 314ms/step - accuracy: 0.5015 - loss: 0.9854Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 314ms/step - accuracy: 0.5011 - loss: 0.9859Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.5007 - loss: 0.9863Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.5004 - loss: 0.9865Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 314ms/step - accuracy: 0.5001 - loss: 0.9869Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.4998 - loss: 0.9872Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.4995 - loss: 0.9876Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 314ms/step - accuracy: 0.4992 - loss: 0.9880Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 314ms/step - accuracy: 0.4989 - loss: 0.9884Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 314ms/step - accuracy: 0.4986 - loss: 0.9887Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 314ms/step - accuracy: 0.4983 - loss: 0.9891Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 314ms/step - accuracy: 0.4979 - loss: 0.9895Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 314ms/step - accuracy: 0.4976 - loss: 0.9898Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 314ms/step - accuracy: 0.4973 - loss: 0.9902Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 314ms/step - accuracy: 0.4971 - loss: 0.9905Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 314ms/step - accuracy: 0.4968 - loss: 0.9908Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 314ms/step - accuracy: 0.4966 - loss: 0.9912Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 314ms/step - accuracy: 0.4963 - loss: 0.9915Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 314ms/step - accuracy: 0.4961 - loss: 0.9919Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.4959 - loss: 0.9922Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 313ms/step - accuracy: 0.4957 - loss: 0.9924Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - accuracy: 0.4955 - loss: 0.9927Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - accuracy: 0.4954 - loss: 0.9930Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 313ms/step - accuracy: 0.4952 - loss: 0.9932Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4950 - loss: 0.9934Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4948 - loss: 0.9936Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4947 - loss: 0.9938Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 348ms/step - accuracy: 0.4945 - loss: 0.9942 - val_accuracy: 0.4706 - val_loss: 0.9377\n",
      "Epoch 11/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 300ms/step - accuracy: 0.3750 - loss: 1.2587Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 297ms/step - accuracy: 0.4219 - loss: 1.1783Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 304ms/step - accuracy: 0.4271 - loss: 1.1558Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 308ms/step - accuracy: 0.4414 - loss: 1.1234Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 308ms/step - accuracy: 0.4556 - loss: 1.0968Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 319ms/step - accuracy: 0.4665 - loss: 1.0752Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 322ms/step - accuracy: 0.4687 - loss: 1.0627Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 321ms/step - accuracy: 0.4707 - loss: 1.0601Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 322ms/step - accuracy: 0.4701 - loss: 1.0573Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 319ms/step - accuracy: 0.4700 - loss: 1.0563Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 319ms/step - accuracy: 0.4716 - loss: 1.0520Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 321ms/step - accuracy: 0.4736 - loss: 1.0474Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 319ms/step - accuracy: 0.4752 - loss: 1.0439Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 318ms/step - accuracy: 0.4764 - loss: 1.0404Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 317ms/step - accuracy: 0.4774 - loss: 1.0372Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.4778 - loss: 1.0352Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 317ms/step - accuracy: 0.4781 - loss: 1.0339Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.4789 - loss: 1.0324Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 315ms/step - accuracy: 0.4800 - loss: 1.0305Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 315ms/step - accuracy: 0.4812 - loss: 1.0281Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 315ms/step - accuracy: 0.4818 - loss: 1.0269Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 314ms/step - accuracy: 0.4821 - loss: 1.0260Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 313ms/step - accuracy: 0.4825 - loss: 1.0254Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 314ms/step - accuracy: 0.4824 - loss: 1.0255Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 313ms/step - accuracy: 0.4820 - loss: 1.0260Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 313ms/step - accuracy: 0.4816 - loss: 1.0263Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 313ms/step - accuracy: 0.4814 - loss: 1.0263Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 313ms/step - accuracy: 0.4811 - loss: 1.0262Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 313ms/step - accuracy: 0.4808 - loss: 1.0263Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 313ms/step - accuracy: 0.4807 - loss: 1.0261Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - accuracy: 0.4804 - loss: 1.0259Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - accuracy: 0.4801 - loss: 1.0258Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - accuracy: 0.4798 - loss: 1.0259Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.4796 - loss: 1.0259Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.4796 - loss: 1.0257Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.4796 - loss: 1.0255Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 313ms/step - accuracy: 0.4796 - loss: 1.0253Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 312ms/step - accuracy: 0.4795 - loss: 1.0251Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 312ms/step - accuracy: 0.4796 - loss: 1.0246Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 312ms/step - accuracy: 0.4797 - loss: 1.0241Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.4798 - loss: 1.0238Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.4798 - loss: 1.0234Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 312ms/step - accuracy: 0.4799 - loss: 1.0229Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - accuracy: 0.4800 - loss: 1.0224Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - accuracy: 0.4801 - loss: 1.0219Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 312ms/step - accuracy: 0.4802 - loss: 1.0214Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.4802 - loss: 1.0211Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.4802 - loss: 1.0209Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 311ms/step - accuracy: 0.4803 - loss: 1.0207Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 311ms/step - accuracy: 0.4804 - loss: 1.0204Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 311ms/step - accuracy: 0.4805 - loss: 1.0201Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 311ms/step - accuracy: 0.4806 - loss: 1.0199Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 311ms/step - accuracy: 0.4807 - loss: 1.0197 Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 311ms/step - accuracy: 0.4807 - loss: 1.0196Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 311ms/step - accuracy: 0.4808 - loss: 1.0196Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 311ms/step - accuracy: 0.4809 - loss: 1.0194Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.4810 - loss: 1.0193Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.4810 - loss: 1.0191Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 311ms/step - accuracy: 0.4811 - loss: 1.0188Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 311ms/step - accuracy: 0.4813 - loss: 1.0186Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 312ms/step - accuracy: 0.4814 - loss: 1.0183Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 311ms/step - accuracy: 0.4815 - loss: 1.0181Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 311ms/step - accuracy: 0.4816 - loss: 1.0179Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 312ms/step - accuracy: 0.4816 - loss: 1.0178Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 312ms/step - accuracy: 0.4817 - loss: 1.0176Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 311ms/step - accuracy: 0.4818 - loss: 1.0175Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.4820 - loss: 1.0173Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 311ms/step - accuracy: 0.4822 - loss: 1.0171Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 312ms/step - accuracy: 0.4824 - loss: 1.0169Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 312ms/step - accuracy: 0.4826 - loss: 1.0167Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 311ms/step - accuracy: 0.4827 - loss: 1.0166Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 311ms/step - accuracy: 0.4829 - loss: 1.0164Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 312ms/step - accuracy: 0.4830 - loss: 1.0161Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 312ms/step - accuracy: 0.4832 - loss: 1.0159Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 312ms/step - accuracy: 0.4833 - loss: 1.0157Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 311ms/step - accuracy: 0.4834 - loss: 1.0154Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 312ms/step - accuracy: 0.4835 - loss: 1.0152Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 311ms/step - accuracy: 0.4837 - loss: 1.0150Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.4838 - loss: 1.0147Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.4838 - loss: 1.0146Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 0.4839 - loss: 1.0144Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.4840 - loss: 1.0142Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.4840 - loss: 1.0140Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.4840 - loss: 1.0140Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 347ms/step - accuracy: 0.4840 - loss: 1.0140 - val_accuracy: 0.4824 - val_loss: 0.9276\n",
      "Epoch 12/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 317ms/step - accuracy: 0.3125 - loss: 1.5313Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 295ms/step - accuracy: 0.3594 - loss: 1.3982Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 301ms/step - accuracy: 0.3715 - loss: 1.3434Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 305ms/step - accuracy: 0.3880 - loss: 1.2963Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 308ms/step - accuracy: 0.3979 - loss: 1.2581Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 307ms/step - accuracy: 0.4045 - loss: 1.2358Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 307ms/step - accuracy: 0.4080 - loss: 1.2207Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 307ms/step - accuracy: 0.4146 - loss: 1.2047Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 310ms/step - accuracy: 0.4187 - loss: 1.1924Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 310ms/step - accuracy: 0.4205 - loss: 1.1882Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 311ms/step - accuracy: 0.4231 - loss: 1.1830Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 310ms/step - accuracy: 0.4256 - loss: 1.1779Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 312ms/step - accuracy: 0.4276 - loss: 1.1732Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 312ms/step - accuracy: 0.4290 - loss: 1.1696Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 312ms/step - accuracy: 0.4301 - loss: 1.1666Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 312ms/step - accuracy: 0.4320 - loss: 1.1627Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 313ms/step - accuracy: 0.4332 - loss: 1.1593Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 313ms/step - accuracy: 0.4346 - loss: 1.1556Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 313ms/step - accuracy: 0.4353 - loss: 1.1533Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 312ms/step - accuracy: 0.4362 - loss: 1.1505Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - accuracy: 0.4371 - loss: 1.1475Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - accuracy: 0.4383 - loss: 1.1442Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - accuracy: 0.4392 - loss: 1.1413Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - accuracy: 0.4404 - loss: 1.1380Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 312ms/step - accuracy: 0.4413 - loss: 1.1347Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 312ms/step - accuracy: 0.4423 - loss: 1.1315Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 313ms/step - accuracy: 0.4429 - loss: 1.1288Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 313ms/step - accuracy: 0.4431 - loss: 1.1267Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 312ms/step - accuracy: 0.4435 - loss: 1.1247Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 313ms/step - accuracy: 0.4440 - loss: 1.1226Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 313ms/step - accuracy: 0.4444 - loss: 1.1207Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - accuracy: 0.4446 - loss: 1.1191Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - accuracy: 0.4450 - loss: 1.1175Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 313ms/step - accuracy: 0.4451 - loss: 1.1162Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.4452 - loss: 1.1150Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 312ms/step - accuracy: 0.4452 - loss: 1.1142Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 313ms/step - accuracy: 0.4451 - loss: 1.1134Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 313ms/step - accuracy: 0.4451 - loss: 1.1126Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 313ms/step - accuracy: 0.4451 - loss: 1.1118Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 313ms/step - accuracy: 0.4452 - loss: 1.1109Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 313ms/step - accuracy: 0.4452 - loss: 1.1100Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 313ms/step - accuracy: 0.4454 - loss: 1.1089Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 313ms/step - accuracy: 0.4457 - loss: 1.1077Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 313ms/step - accuracy: 0.4458 - loss: 1.1066Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 313ms/step - accuracy: 0.4459 - loss: 1.1057Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 313ms/step - accuracy: 0.4459 - loss: 1.1049Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.4460 - loss: 1.1041Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 313ms/step - accuracy: 0.4460 - loss: 1.1032Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 312ms/step - accuracy: 0.4461 - loss: 1.1022Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.4461 - loss: 1.1014Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.4463 - loss: 1.1004Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 312ms/step - accuracy: 0.4465 - loss: 1.0994Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 312ms/step - accuracy: 0.4467 - loss: 1.0984 Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 312ms/step - accuracy: 0.4469 - loss: 1.0974Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 312ms/step - accuracy: 0.4472 - loss: 1.0964Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 313ms/step - accuracy: 0.4474 - loss: 1.0955Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 313ms/step - accuracy: 0.4476 - loss: 1.0945Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 313ms/step - accuracy: 0.4477 - loss: 1.0936Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 313ms/step - accuracy: 0.4479 - loss: 1.0928Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.4481 - loss: 1.0921Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.4482 - loss: 1.0914Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 313ms/step - accuracy: 0.4483 - loss: 1.0907Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.4485 - loss: 1.0900Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.4486 - loss: 1.0893Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 313ms/step - accuracy: 0.4488 - loss: 1.0886Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.4489 - loss: 1.0879Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 312ms/step - accuracy: 0.4490 - loss: 1.0873Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 313ms/step - accuracy: 0.4492 - loss: 1.0867Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 313ms/step - accuracy: 0.4492 - loss: 1.0861Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 313ms/step - accuracy: 0.4493 - loss: 1.0855Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 313ms/step - accuracy: 0.4494 - loss: 1.0849Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 313ms/step - accuracy: 0.4494 - loss: 1.0844Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 312ms/step - accuracy: 0.4495 - loss: 1.0838Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 312ms/step - accuracy: 0.4497 - loss: 1.0832Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 312ms/step - accuracy: 0.4498 - loss: 1.0827Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 312ms/step - accuracy: 0.4499 - loss: 1.0821Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 312ms/step - accuracy: 0.4501 - loss: 1.0816Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 312ms/step - accuracy: 0.4502 - loss: 1.0811Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - accuracy: 0.4504 - loss: 1.0806Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - accuracy: 0.4505 - loss: 1.0802Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 312ms/step - accuracy: 0.4507 - loss: 1.0798Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4508 - loss: 1.0793Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4509 - loss: 1.0789Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.4511 - loss: 1.0786Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 349ms/step - accuracy: 0.4513 - loss: 1.0777 - val_accuracy: 0.4294 - val_loss: 0.9790\n",
      "Epoch 13/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 305ms/step - accuracy: 0.4375 - loss: 0.8713Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 309ms/step - accuracy: 0.4375 - loss: 0.8964Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 311ms/step - accuracy: 0.4236 - loss: 0.9253Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 312ms/step - accuracy: 0.4115 - loss: 0.9410Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 313ms/step - accuracy: 0.4042 - loss: 0.9581Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 311ms/step - accuracy: 0.3993 - loss: 0.9817Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 312ms/step - accuracy: 0.3958 - loss: 1.0021Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 312ms/step - accuracy: 0.3942 - loss: 1.0144Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 316ms/step - accuracy: 0.3928 - loss: 1.0252Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 315ms/step - accuracy: 0.3929 - loss: 1.0329Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 316ms/step - accuracy: 0.3949 - loss: 1.0364Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 318ms/step - accuracy: 0.3959 - loss: 1.0398Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 319ms/step - accuracy: 0.3965 - loss: 1.0435Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 318ms/step - accuracy: 0.3972 - loss: 1.0476Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 317ms/step - accuracy: 0.3976 - loss: 1.0523Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 316ms/step - accuracy: 0.3984 - loss: 1.0558Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 315ms/step - accuracy: 0.3994 - loss: 1.0585Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 314ms/step - accuracy: 0.4008 - loss: 1.0605Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 314ms/step - accuracy: 0.4025 - loss: 1.0618Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 313ms/step - accuracy: 0.4041 - loss: 1.0631Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - accuracy: 0.4057 - loss: 1.0641Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 312ms/step - accuracy: 0.4079 - loss: 1.0641Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 311ms/step - accuracy: 0.4102 - loss: 1.0640Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 311ms/step - accuracy: 0.4118 - loss: 1.0640Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 312ms/step - accuracy: 0.4135 - loss: 1.0642Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 312ms/step - accuracy: 0.4151 - loss: 1.0641Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 312ms/step - accuracy: 0.4166 - loss: 1.0636Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 312ms/step - accuracy: 0.4181 - loss: 1.0630Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 313ms/step - accuracy: 0.4196 - loss: 1.0623Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 312ms/step - accuracy: 0.4210 - loss: 1.0617Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - accuracy: 0.4224 - loss: 1.0608Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 312ms/step - accuracy: 0.4237 - loss: 1.0600Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 311ms/step - accuracy: 0.4249 - loss: 1.0591Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 311ms/step - accuracy: 0.4261 - loss: 1.0580Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 311ms/step - accuracy: 0.4273 - loss: 1.0570Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 311ms/step - accuracy: 0.4286 - loss: 1.0558Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 311ms/step - accuracy: 0.4298 - loss: 1.0547Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 311ms/step - accuracy: 0.4311 - loss: 1.0536Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 311ms/step - accuracy: 0.4322 - loss: 1.0526Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 311ms/step - accuracy: 0.4334 - loss: 1.0515Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 310ms/step - accuracy: 0.4345 - loss: 1.0504Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 310ms/step - accuracy: 0.4356 - loss: 1.0494Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 310ms/step - accuracy: 0.4367 - loss: 1.0484Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 310ms/step - accuracy: 0.4378 - loss: 1.0474Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 310ms/step - accuracy: 0.4388 - loss: 1.0465Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 309ms/step - accuracy: 0.4397 - loss: 1.0454Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 309ms/step - accuracy: 0.4407 - loss: 1.0446Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 309ms/step - accuracy: 0.4415 - loss: 1.0438Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 310ms/step - accuracy: 0.4424 - loss: 1.0431Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 309ms/step - accuracy: 0.4431 - loss: 1.0425Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 309ms/step - accuracy: 0.4439 - loss: 1.0420Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 309ms/step - accuracy: 0.4445 - loss: 1.0415Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 309ms/step - accuracy: 0.4452 - loss: 1.0410 Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 309ms/step - accuracy: 0.4458 - loss: 1.0404Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 309ms/step - accuracy: 0.4465 - loss: 1.0398Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 309ms/step - accuracy: 0.4472 - loss: 1.0392Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 309ms/step - accuracy: 0.4478 - loss: 1.0387Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 309ms/step - accuracy: 0.4484 - loss: 1.0382Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 309ms/step - accuracy: 0.4490 - loss: 1.0378Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.4496 - loss: 1.0374Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.4501 - loss: 1.0370Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 309ms/step - accuracy: 0.4507 - loss: 1.0367Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 309ms/step - accuracy: 0.4512 - loss: 1.0363Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 309ms/step - accuracy: 0.4517 - loss: 1.0360Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 309ms/step - accuracy: 0.4521 - loss: 1.0357Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 309ms/step - accuracy: 0.4527 - loss: 1.0353Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 309ms/step - accuracy: 0.4531 - loss: 1.0350Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 309ms/step - accuracy: 0.4536 - loss: 1.0348Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 309ms/step - accuracy: 0.4540 - loss: 1.0345Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 309ms/step - accuracy: 0.4545 - loss: 1.0342Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 309ms/step - accuracy: 0.4549 - loss: 1.0340Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 309ms/step - accuracy: 0.4553 - loss: 1.0337Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 0.4556 - loss: 1.0335Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 0.4560 - loss: 1.0332Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 0.4563 - loss: 1.0329Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.4566 - loss: 1.0326Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.4568 - loss: 1.0324Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.4570 - loss: 1.0323Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - accuracy: 0.4572 - loss: 1.0321Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - accuracy: 0.4575 - loss: 1.0320Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 309ms/step - accuracy: 0.4577 - loss: 1.0317Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.4579 - loss: 1.0315Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.4582 - loss: 1.0314Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.4584 - loss: 1.0312Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 346ms/step - accuracy: 0.4590 - loss: 1.0309 - val_accuracy: 0.4765 - val_loss: 0.8656\n",
      "Epoch 14/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 313ms/step - accuracy: 0.6250 - loss: 0.7510Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 307ms/step - accuracy: 0.6094 - loss: 0.8011Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 301ms/step - accuracy: 0.5729 - loss: 0.8431Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 299ms/step - accuracy: 0.5508 - loss: 0.8643Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 299ms/step - accuracy: 0.5481 - loss: 0.8682Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 298ms/step - accuracy: 0.5453 - loss: 0.8777Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 299ms/step - accuracy: 0.5401 - loss: 0.8868Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 300ms/step - accuracy: 0.5341 - loss: 0.8997Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 301ms/step - accuracy: 0.5311 - loss: 0.9080Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 301ms/step - accuracy: 0.5292 - loss: 0.9143Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 302ms/step - accuracy: 0.5281 - loss: 0.9174Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 305ms/step - accuracy: 0.5275 - loss: 0.9191Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 305ms/step - accuracy: 0.5261 - loss: 0.9228Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 305ms/step - accuracy: 0.5252 - loss: 0.9252Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 305ms/step - accuracy: 0.5241 - loss: 0.9277Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 0.5226 - loss: 0.9299Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 305ms/step - accuracy: 0.5211 - loss: 0.9319Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 0.5195 - loss: 0.9339Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 304ms/step - accuracy: 0.5178 - loss: 0.9365Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 305ms/step - accuracy: 0.5163 - loss: 0.9387Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 305ms/step - accuracy: 0.5146 - loss: 0.9410Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 304ms/step - accuracy: 0.5132 - loss: 0.9430Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 304ms/step - accuracy: 0.5113 - loss: 0.9456Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 305ms/step - accuracy: 0.5096 - loss: 0.9481Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 305ms/step - accuracy: 0.5079 - loss: 0.9505Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 305ms/step - accuracy: 0.5066 - loss: 0.9523Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 304ms/step - accuracy: 0.5054 - loss: 0.9541Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 304ms/step - accuracy: 0.5041 - loss: 0.9562Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 304ms/step - accuracy: 0.5032 - loss: 0.9580Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 304ms/step - accuracy: 0.5024 - loss: 0.9594Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 304ms/step - accuracy: 0.5017 - loss: 0.9610Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 304ms/step - accuracy: 0.5011 - loss: 0.9623Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - accuracy: 0.5006 - loss: 0.9636Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - accuracy: 0.5001 - loss: 0.9647Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 304ms/step - accuracy: 0.4995 - loss: 0.9658Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 303ms/step - accuracy: 0.4991 - loss: 0.9666Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 303ms/step - accuracy: 0.4988 - loss: 0.9674Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 304ms/step - accuracy: 0.4985 - loss: 0.9681Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 304ms/step - accuracy: 0.4983 - loss: 0.9687Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 304ms/step - accuracy: 0.4980 - loss: 0.9695Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 304ms/step - accuracy: 0.4978 - loss: 0.9703Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 304ms/step - accuracy: 0.4974 - loss: 0.9713Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 304ms/step - accuracy: 0.4972 - loss: 0.9722Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 304ms/step - accuracy: 0.4971 - loss: 0.9729Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 304ms/step - accuracy: 0.4968 - loss: 0.9738Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.4965 - loss: 0.9748Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.4962 - loss: 0.9758Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 304ms/step - accuracy: 0.4959 - loss: 0.9767Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 304ms/step - accuracy: 0.4956 - loss: 0.9777Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 304ms/step - accuracy: 0.4953 - loss: 0.9786Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 304ms/step - accuracy: 0.4951 - loss: 0.9794Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 304ms/step - accuracy: 0.4948 - loss: 0.9802Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 304ms/step - accuracy: 0.4947 - loss: 0.9809 Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 304ms/step - accuracy: 0.4946 - loss: 0.9817Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 304ms/step - accuracy: 0.4944 - loss: 0.9825Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 305ms/step - accuracy: 0.4943 - loss: 0.9832Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 305ms/step - accuracy: 0.4941 - loss: 0.9839Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 305ms/step - accuracy: 0.4940 - loss: 0.9846Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.4939 - loss: 0.9852Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.4938 - loss: 0.9858Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.4937 - loss: 0.9865Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 305ms/step - accuracy: 0.4936 - loss: 0.9872Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.4935 - loss: 0.9878Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.4933 - loss: 0.9885Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 305ms/step - accuracy: 0.4932 - loss: 0.9891Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.4931 - loss: 0.9896Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.4931 - loss: 0.9901Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.4930 - loss: 0.9907Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 305ms/step - accuracy: 0.4930 - loss: 0.9911Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 306ms/step - accuracy: 0.4930 - loss: 0.9914Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 306ms/step - accuracy: 0.4930 - loss: 0.9917Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.4930 - loss: 0.9919Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.4931 - loss: 0.9922Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.4931 - loss: 0.9924Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.4931 - loss: 0.9927Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.4931 - loss: 0.9929Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.4932 - loss: 0.9931Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.4933 - loss: 0.9933Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.4934 - loss: 0.9934Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.4934 - loss: 0.9935Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.4935 - loss: 0.9936Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.4936 - loss: 0.9937Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.4937 - loss: 0.9938Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.4937 - loss: 0.9939Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 345ms/step - accuracy: 0.4938 - loss: 0.9941 - val_accuracy: 0.4941 - val_loss: 0.9260\n",
      "Epoch 15/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 318ms/step - accuracy: 0.6250 - loss: 1.0234Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 315ms/step - accuracy: 0.6094 - loss: 0.9628Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 316ms/step - accuracy: 0.6076 - loss: 0.9357Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 312ms/step - accuracy: 0.6081 - loss: 0.9211Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 310ms/step - accuracy: 0.5990 - loss: 0.9170Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 308ms/step - accuracy: 0.5964 - loss: 0.9163Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 308ms/step - accuracy: 0.5928 - loss: 0.9161Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 308ms/step - accuracy: 0.5910 - loss: 0.9117Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 308ms/step - accuracy: 0.5870 - loss: 0.9146Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 307ms/step - accuracy: 0.5846 - loss: 0.9193Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 307ms/step - accuracy: 0.5805 - loss: 0.9248Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 307ms/step - accuracy: 0.5768 - loss: 0.9283Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 306ms/step - accuracy: 0.5724 - loss: 0.9329Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 306ms/step - accuracy: 0.5675 - loss: 0.9388Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 305ms/step - accuracy: 0.5630 - loss: 0.9443Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 307ms/step - accuracy: 0.5584 - loss: 0.9496Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 308ms/step - accuracy: 0.5541 - loss: 0.9538Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 308ms/step - accuracy: 0.5503 - loss: 0.9570Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 307ms/step - accuracy: 0.5468 - loss: 0.9595Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 307ms/step - accuracy: 0.5437 - loss: 0.9620Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 306ms/step - accuracy: 0.5412 - loss: 0.9639Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 306ms/step - accuracy: 0.5388 - loss: 0.9657Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 306ms/step - accuracy: 0.5368 - loss: 0.9672Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 306ms/step - accuracy: 0.5351 - loss: 0.9692Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 306ms/step - accuracy: 0.5335 - loss: 0.9711Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 306ms/step - accuracy: 0.5319 - loss: 0.9728Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 306ms/step - accuracy: 0.5306 - loss: 0.9744Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 306ms/step - accuracy: 0.5290 - loss: 0.9761Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 306ms/step - accuracy: 0.5274 - loss: 0.9780Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 306ms/step - accuracy: 0.5261 - loss: 0.9795Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 307ms/step - accuracy: 0.5252 - loss: 0.9806Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 308ms/step - accuracy: 0.5243 - loss: 0.9814Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - accuracy: 0.5235 - loss: 0.9820Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - accuracy: 0.5225 - loss: 0.9828Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - accuracy: 0.5215 - loss: 0.9836Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 307ms/step - accuracy: 0.5204 - loss: 0.9843Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 307ms/step - accuracy: 0.5196 - loss: 0.9848Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 307ms/step - accuracy: 0.5187 - loss: 0.9856Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 306ms/step - accuracy: 0.5179 - loss: 0.9862Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 306ms/step - accuracy: 0.5172 - loss: 0.9867Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 306ms/step - accuracy: 0.5168 - loss: 0.9871Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 306ms/step - accuracy: 0.5162 - loss: 0.9875Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 306ms/step - accuracy: 0.5157 - loss: 0.9877Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 306ms/step - accuracy: 0.5153 - loss: 0.9879Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 306ms/step - accuracy: 0.5149 - loss: 0.9880Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 306ms/step - accuracy: 0.5146 - loss: 0.9881Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 307ms/step - accuracy: 0.5142 - loss: 0.9882Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 307ms/step - accuracy: 0.5139 - loss: 0.9882Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 307ms/step - accuracy: 0.5136 - loss: 0.9883Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 307ms/step - accuracy: 0.5134 - loss: 0.9883Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 307ms/step - accuracy: 0.5131 - loss: 0.9884Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 307ms/step - accuracy: 0.5129 - loss: 0.9885Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 307ms/step - accuracy: 0.5126 - loss: 0.9886 Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 307ms/step - accuracy: 0.5123 - loss: 0.9887Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 307ms/step - accuracy: 0.5120 - loss: 0.9889Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 307ms/step - accuracy: 0.5117 - loss: 0.9890Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 307ms/step - accuracy: 0.5113 - loss: 0.9892Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 307ms/step - accuracy: 0.5110 - loss: 0.9893Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.5107 - loss: 0.9894Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.5103 - loss: 0.9897Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 306ms/step - accuracy: 0.5100 - loss: 0.9899Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 307ms/step - accuracy: 0.5096 - loss: 0.9901Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 307ms/step - accuracy: 0.5093 - loss: 0.9903Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 307ms/step - accuracy: 0.5089 - loss: 0.9906Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 307ms/step - accuracy: 0.5085 - loss: 0.9908Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 306ms/step - accuracy: 0.5082 - loss: 0.9910Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 306ms/step - accuracy: 0.5079 - loss: 0.9912Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 306ms/step - accuracy: 0.5076 - loss: 0.9914Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 306ms/step - accuracy: 0.5074 - loss: 0.9915Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 306ms/step - accuracy: 0.5071 - loss: 0.9917Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 306ms/step - accuracy: 0.5069 - loss: 0.9919Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.5066 - loss: 0.9921Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.5064 - loss: 0.9923Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.5062 - loss: 0.9924Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.5060 - loss: 0.9925Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.5057 - loss: 0.9927Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.5055 - loss: 0.9929Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.5053 - loss: 0.9931Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.5051 - loss: 0.9932Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.5048 - loss: 0.9934Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 306ms/step - accuracy: 0.5046 - loss: 0.9936Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.5044 - loss: 0.9938Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.5042 - loss: 0.9940Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.5040 - loss: 0.9942Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 343ms/step - accuracy: 0.5036 - loss: 0.9946 - val_accuracy: 0.5059 - val_loss: 0.9627\n",
      "Epoch 16/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 301ms/step - accuracy: 0.5625 - loss: 0.7983Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 295ms/step - accuracy: 0.5781 - loss: 0.7942Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 291ms/step - accuracy: 0.5868 - loss: 0.8049Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 293ms/step - accuracy: 0.5846 - loss: 0.8197Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 294ms/step - accuracy: 0.5827 - loss: 0.8375Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 298ms/step - accuracy: 0.5793 - loss: 0.8499Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 297ms/step - accuracy: 0.5757 - loss: 0.8637Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 297ms/step - accuracy: 0.5740 - loss: 0.8714Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 297ms/step - accuracy: 0.5735 - loss: 0.8794Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 297ms/step - accuracy: 0.5705 - loss: 0.8887Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 297ms/step - accuracy: 0.5683 - loss: 0.8951Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 298ms/step - accuracy: 0.5665 - loss: 0.9013Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 300ms/step - accuracy: 0.5651 - loss: 0.9055Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 301ms/step - accuracy: 0.5633 - loss: 0.9094Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 301ms/step - accuracy: 0.5616 - loss: 0.9130Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 301ms/step - accuracy: 0.5599 - loss: 0.9157Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 301ms/step - accuracy: 0.5583 - loss: 0.9186Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.5566 - loss: 0.9215Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 300ms/step - accuracy: 0.5543 - loss: 0.9246Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 300ms/step - accuracy: 0.5519 - loss: 0.9277Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 300ms/step - accuracy: 0.5498 - loss: 0.9302Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 300ms/step - accuracy: 0.5479 - loss: 0.9323Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 300ms/step - accuracy: 0.5462 - loss: 0.9343Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 300ms/step - accuracy: 0.5442 - loss: 0.9366Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 300ms/step - accuracy: 0.5427 - loss: 0.9388Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 300ms/step - accuracy: 0.5411 - loss: 0.9406Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 300ms/step - accuracy: 0.5398 - loss: 0.9420Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 301ms/step - accuracy: 0.5385 - loss: 0.9435Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 301ms/step - accuracy: 0.5372 - loss: 0.9450Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 301ms/step - accuracy: 0.5359 - loss: 0.9464Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 301ms/step - accuracy: 0.5346 - loss: 0.9477Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 301ms/step - accuracy: 0.5331 - loss: 0.9489Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 301ms/step - accuracy: 0.5318 - loss: 0.9500Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 301ms/step - accuracy: 0.5304 - loss: 0.9511Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 301ms/step - accuracy: 0.5290 - loss: 0.9522Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 301ms/step - accuracy: 0.5277 - loss: 0.9532Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 301ms/step - accuracy: 0.5263 - loss: 0.9543Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 301ms/step - accuracy: 0.5251 - loss: 0.9553Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 301ms/step - accuracy: 0.5238 - loss: 0.9566Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 302ms/step - accuracy: 0.5225 - loss: 0.9579Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 302ms/step - accuracy: 0.5212 - loss: 0.9593Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 303ms/step - accuracy: 0.5199 - loss: 0.9605Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 303ms/step - accuracy: 0.5187 - loss: 0.9618Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 302ms/step - accuracy: 0.5177 - loss: 0.9628Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 302ms/step - accuracy: 0.5166 - loss: 0.9638Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 302ms/step - accuracy: 0.5155 - loss: 0.9650Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 302ms/step - accuracy: 0.5144 - loss: 0.9661Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.5134 - loss: 0.9670Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 302ms/step - accuracy: 0.5124 - loss: 0.9680Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 302ms/step - accuracy: 0.5114 - loss: 0.9690Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 302ms/step - accuracy: 0.5105 - loss: 0.9699Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5097 - loss: 0.9708 Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5089 - loss: 0.9716Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5082 - loss: 0.9724Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5074 - loss: 0.9732Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 302ms/step - accuracy: 0.5066 - loss: 0.9741Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 302ms/step - accuracy: 0.5058 - loss: 0.9750Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 303ms/step - accuracy: 0.5050 - loss: 0.9759Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.5042 - loss: 0.9768Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.5035 - loss: 0.9776Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.5027 - loss: 0.9784Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - accuracy: 0.5019 - loss: 0.9794Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - accuracy: 0.5012 - loss: 0.9802Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - accuracy: 0.5005 - loss: 0.9810Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 302ms/step - accuracy: 0.4998 - loss: 0.9817Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.4992 - loss: 0.9824Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.4986 - loss: 0.9831Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.4981 - loss: 0.9838Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 302ms/step - accuracy: 0.4975 - loss: 0.9844Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 303ms/step - accuracy: 0.4970 - loss: 0.9851Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 303ms/step - accuracy: 0.4965 - loss: 0.9857Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 303ms/step - accuracy: 0.4960 - loss: 0.9862Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 303ms/step - accuracy: 0.4956 - loss: 0.9867Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 304ms/step - accuracy: 0.4952 - loss: 0.9872Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 303ms/step - accuracy: 0.4949 - loss: 0.9876Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 303ms/step - accuracy: 0.4945 - loss: 0.9881Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 303ms/step - accuracy: 0.4942 - loss: 0.9885Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 303ms/step - accuracy: 0.4939 - loss: 0.9888Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 0.4936 - loss: 0.9892Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 0.4933 - loss: 0.9895Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 0.4930 - loss: 0.9898Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.4927 - loss: 0.9901Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.4924 - loss: 0.9904Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.4922 - loss: 0.9907Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 341ms/step - accuracy: 0.4917 - loss: 0.9912 - val_accuracy: 0.5000 - val_loss: 1.0064\n",
      "Epoch 17/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 310ms/step - accuracy: 0.3750 - loss: 0.9701Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 302ms/step - accuracy: 0.3594 - loss: 1.0235Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 305ms/step - accuracy: 0.3854 - loss: 1.0068Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 306ms/step - accuracy: 0.3945 - loss: 1.0195Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 318ms/step - accuracy: 0.4031 - loss: 1.0212Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 315ms/step - accuracy: 0.4089 - loss: 1.0267Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 314ms/step - accuracy: 0.4117 - loss: 1.0310Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 311ms/step - accuracy: 0.4120 - loss: 1.0410Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 308ms/step - accuracy: 0.4117 - loss: 1.0504Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 306ms/step - accuracy: 0.4124 - loss: 1.0590Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 304ms/step - accuracy: 0.4132 - loss: 1.0655Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 302ms/step - accuracy: 0.4130 - loss: 1.0746Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 300ms/step - accuracy: 0.4145 - loss: 1.0797Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 299ms/step - accuracy: 0.4162 - loss: 1.0832Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 297ms/step - accuracy: 0.4193 - loss: 1.0843Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 297ms/step - accuracy: 0.4219 - loss: 1.0848Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 296ms/step - accuracy: 0.4249 - loss: 1.0840Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 295ms/step - accuracy: 0.4276 - loss: 1.0826Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 294ms/step - accuracy: 0.4298 - loss: 1.0815Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 293ms/step - accuracy: 0.4318 - loss: 1.0805Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 293ms/step - accuracy: 0.4340 - loss: 1.0789Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 292ms/step - accuracy: 0.4364 - loss: 1.0770Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 291ms/step - accuracy: 0.4386 - loss: 1.0749Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 291ms/step - accuracy: 0.4407 - loss: 1.0727Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 290ms/step - accuracy: 0.4429 - loss: 1.0704Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 290ms/step - accuracy: 0.4451 - loss: 1.0677Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 289ms/step - accuracy: 0.4473 - loss: 1.0650Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - accuracy: 0.4491 - loss: 1.0629Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 290ms/step - accuracy: 0.4510 - loss: 1.0609Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - accuracy: 0.4527 - loss: 1.0591Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - accuracy: 0.4544 - loss: 1.0574Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 291ms/step - accuracy: 0.4559 - loss: 1.0558Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 290ms/step - accuracy: 0.4574 - loss: 1.0541Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 290ms/step - accuracy: 0.4588 - loss: 1.0525Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 290ms/step - accuracy: 0.4600 - loss: 1.0509Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 290ms/step - accuracy: 0.4611 - loss: 1.0496Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 290ms/step - accuracy: 0.4623 - loss: 1.0482Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.4633 - loss: 1.0471Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.4641 - loss: 1.0462Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 289ms/step - accuracy: 0.4649 - loss: 1.0452Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 289ms/step - accuracy: 0.4656 - loss: 1.0444Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 290ms/step - accuracy: 0.4664 - loss: 1.0434Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 291ms/step - accuracy: 0.4672 - loss: 1.0423Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 291ms/step - accuracy: 0.4679 - loss: 1.0413Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 291ms/step - accuracy: 0.4686 - loss: 1.0402Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 292ms/step - accuracy: 0.4693 - loss: 1.0392Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 292ms/step - accuracy: 0.4699 - loss: 1.0381Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.4705 - loss: 1.0371Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 292ms/step - accuracy: 0.4710 - loss: 1.0361Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 293ms/step - accuracy: 0.4716 - loss: 1.0352Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 292ms/step - accuracy: 0.4722 - loss: 1.0343 Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 293ms/step - accuracy: 0.4728 - loss: 1.0333Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 293ms/step - accuracy: 0.4735 - loss: 1.0324Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 293ms/step - accuracy: 0.4741 - loss: 1.0314Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 294ms/step - accuracy: 0.4747 - loss: 1.0305Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 294ms/step - accuracy: 0.4753 - loss: 1.0295Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 294ms/step - accuracy: 0.4758 - loss: 1.0286Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.4764 - loss: 1.0277Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.4770 - loss: 1.0268Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 294ms/step - accuracy: 0.4775 - loss: 1.0260Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 295ms/step - accuracy: 0.4781 - loss: 1.0252Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - accuracy: 0.4786 - loss: 1.0244Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - accuracy: 0.4790 - loss: 1.0236Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 295ms/step - accuracy: 0.4795 - loss: 1.0228Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.4799 - loss: 1.0220Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.4803 - loss: 1.0213Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.4806 - loss: 1.0206Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 0.4810 - loss: 1.0199Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 296ms/step - accuracy: 0.4813 - loss: 1.0191Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 296ms/step - accuracy: 0.4817 - loss: 1.0184Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 297ms/step - accuracy: 0.4820 - loss: 1.0177Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 297ms/step - accuracy: 0.4823 - loss: 1.0171Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 297ms/step - accuracy: 0.4826 - loss: 1.0165Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 297ms/step - accuracy: 0.4829 - loss: 1.0160Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 297ms/step - accuracy: 0.4831 - loss: 1.0154Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 298ms/step - accuracy: 0.4834 - loss: 1.0150Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 298ms/step - accuracy: 0.4837 - loss: 1.0145Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 298ms/step - accuracy: 0.4839 - loss: 1.0141Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - accuracy: 0.4841 - loss: 1.0137Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - accuracy: 0.4844 - loss: 1.0133Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 298ms/step - accuracy: 0.4847 - loss: 1.0130Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.4849 - loss: 1.0126Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.4852 - loss: 1.0122Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.4854 - loss: 1.0119Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 338ms/step - accuracy: 0.4858 - loss: 1.0113 - val_accuracy: 0.5588 - val_loss: 0.8832\n",
      "Epoch 18/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 299ms/step - accuracy: 0.3750 - loss: 1.0233Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 364ms/step - accuracy: 0.4219 - loss: 0.9665Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 351ms/step - accuracy: 0.4271 - loss: 0.9639Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 385ms/step - accuracy: 0.4258 - loss: 0.9745Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 382ms/step - accuracy: 0.4356 - loss: 0.9802Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 373ms/step - accuracy: 0.4411 - loss: 0.9823Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 378ms/step - accuracy: 0.4419 - loss: 0.9902Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 374ms/step - accuracy: 0.4443 - loss: 0.9931Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 369ms/step - accuracy: 0.4497 - loss: 0.9912Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 371ms/step - accuracy: 0.4522 - loss: 0.9921Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 371ms/step - accuracy: 0.4540 - loss: 0.9944Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 368ms/step - accuracy: 0.4561 - loss: 0.9953Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 368ms/step - accuracy: 0.4587 - loss: 0.9959Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 367ms/step - accuracy: 0.4620 - loss: 0.9952Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 364ms/step - accuracy: 0.4640 - loss: 0.9951Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 365ms/step - accuracy: 0.4662 - loss: 0.9941Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 365ms/step - accuracy: 0.4673 - loss: 0.9933Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 362ms/step - accuracy: 0.4682 - loss: 0.9928Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 364ms/step - accuracy: 0.4693 - loss: 0.9918Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 365ms/step - accuracy: 0.4701 - loss: 0.9908Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 361ms/step - accuracy: 0.4710 - loss: 0.9899Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 362ms/step - accuracy: 0.4720 - loss: 0.9890Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 362ms/step - accuracy: 0.4726 - loss: 0.9887Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 360ms/step - accuracy: 0.4735 - loss: 0.9881Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 360ms/step - accuracy: 0.4743 - loss: 0.9874Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 359ms/step - accuracy: 0.4749 - loss: 0.9869Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 360ms/step - accuracy: 0.4754 - loss: 0.9870Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 358ms/step - accuracy: 0.4757 - loss: 0.9875Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 360ms/step - accuracy: 0.4758 - loss: 0.9880Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 361ms/step - accuracy: 0.4760 - loss: 0.9884Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 359ms/step - accuracy: 0.4762 - loss: 0.9886Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 359ms/step - accuracy: 0.4763 - loss: 0.9888Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 357ms/step - accuracy: 0.4764 - loss: 0.9887Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 358ms/step - accuracy: 0.4763 - loss: 0.9891Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 358ms/step - accuracy: 0.4764 - loss: 0.9894Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 357ms/step - accuracy: 0.4762 - loss: 0.9899Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 357ms/step - accuracy: 0.4760 - loss: 0.9905Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 358ms/step - accuracy: 0.4760 - loss: 0.9909Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 357ms/step - accuracy: 0.4760 - loss: 0.9912Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 357ms/step - accuracy: 0.4759 - loss: 0.9916Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 357ms/step - accuracy: 0.4757 - loss: 0.9920Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 356ms/step - accuracy: 0.4757 - loss: 0.9922Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 356ms/step - accuracy: 0.4757 - loss: 0.9925Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 355ms/step - accuracy: 0.4755 - loss: 0.9930Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 356ms/step - accuracy: 0.4754 - loss: 0.9936Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 355ms/step - accuracy: 0.4752 - loss: 0.9942Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 355ms/step - accuracy: 0.4752 - loss: 0.9946Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 355ms/step - accuracy: 0.4751 - loss: 0.9950Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 354ms/step - accuracy: 0.4751 - loss: 0.9953Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 354ms/step - accuracy: 0.4750 - loss: 0.9956Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 354ms/step - accuracy: 0.4750 - loss: 0.9959Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 354ms/step - accuracy: 0.4751 - loss: 0.9961Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 355ms/step - accuracy: 0.4752 - loss: 0.9964Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 354ms/step - accuracy: 0.4753 - loss: 0.9967Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 355ms/step - accuracy: 0.4754 - loss: 0.9970Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 355ms/step - accuracy: 0.4755 - loss: 0.9974Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 354ms/step - accuracy: 0.4756 - loss: 0.9977 Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 355ms/step - accuracy: 0.4757 - loss: 0.9980Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 354ms/step - accuracy: 0.4758 - loss: 0.9982Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.4759 - loss: 0.9986Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.4760 - loss: 0.9988Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.4761 - loss: 0.9992Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 355ms/step - accuracy: 0.4762 - loss: 0.9995Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 354ms/step - accuracy: 0.4763 - loss: 0.9997Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 353ms/step - accuracy: 0.4764 - loss: 0.9999Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 352ms/step - accuracy: 0.4766 - loss: 1.0000Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 352ms/step - accuracy: 0.4767 - loss: 1.0000Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 352ms/step - accuracy: 0.4769 - loss: 1.0001Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 351ms/step - accuracy: 0.4770 - loss: 1.0002Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 350ms/step - accuracy: 0.4772 - loss: 1.0002Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 350ms/step - accuracy: 0.4774 - loss: 1.0003Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 349ms/step - accuracy: 0.4775 - loss: 1.0004Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 348ms/step - accuracy: 0.4777 - loss: 1.0004Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 348ms/step - accuracy: 0.4779 - loss: 1.0005Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 347ms/step - accuracy: 0.4780 - loss: 1.0005Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 347ms/step - accuracy: 0.4782 - loss: 1.0005Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 347ms/step - accuracy: 0.4784 - loss: 1.0005Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 346ms/step - accuracy: 0.4786 - loss: 1.0004Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 345ms/step - accuracy: 0.4787 - loss: 1.0004Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 345ms/step - accuracy: 0.4789 - loss: 1.0003Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 0.4790 - loss: 1.0003Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 344ms/step - accuracy: 0.4791 - loss: 1.0003Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.4793 - loss: 1.0003Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 343ms/step - accuracy: 0.4794 - loss: 1.0002Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 380ms/step - accuracy: 0.4798 - loss: 1.0001 - val_accuracy: 0.4824 - val_loss: 0.9110\n",
      "Epoch 19/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 291ms/step - accuracy: 0.6875 - loss: 0.7973Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 299ms/step - accuracy: 0.6406 - loss: 0.8741Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 300ms/step - accuracy: 0.6146 - loss: 0.9290Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 301ms/step - accuracy: 0.5938 - loss: 0.9523Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 297ms/step - accuracy: 0.5750 - loss: 0.9683Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 298ms/step - accuracy: 0.5642 - loss: 0.9707Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 297ms/step - accuracy: 0.5576 - loss: 0.9698Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 294ms/step - accuracy: 0.5514 - loss: 0.9713Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 293ms/step - accuracy: 0.5441 - loss: 0.9752Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 293ms/step - accuracy: 0.5372 - loss: 0.9786Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 300ms/step - accuracy: 0.5313 - loss: 0.9833Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 302ms/step - accuracy: 0.5269 - loss: 0.9868Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 301ms/step - accuracy: 0.5226 - loss: 0.9904Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 300ms/step - accuracy: 0.5197 - loss: 0.9930Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.5173 - loss: 0.9951Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.5148 - loss: 0.9972Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 300ms/step - accuracy: 0.5126 - loss: 0.9990Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 299ms/step - accuracy: 0.5109 - loss: 0.9997Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - accuracy: 0.5102 - loss: 1.0000Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - accuracy: 0.5089 - loss: 1.0013Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 299ms/step - accuracy: 0.5076 - loss: 1.0028Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 299ms/step - accuracy: 0.5062 - loss: 1.0043Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 299ms/step - accuracy: 0.5047 - loss: 1.0057Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 299ms/step - accuracy: 0.5031 - loss: 1.0072Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 299ms/step - accuracy: 0.5013 - loss: 1.0088Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 300ms/step - accuracy: 0.4997 - loss: 1.0103Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 301ms/step - accuracy: 0.4984 - loss: 1.0114Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 302ms/step - accuracy: 0.4971 - loss: 1.0122Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 302ms/step - accuracy: 0.4959 - loss: 1.0128Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 301ms/step - accuracy: 0.4949 - loss: 1.0133Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 300ms/step - accuracy: 0.4939 - loss: 1.0135Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.4930 - loss: 1.0138Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.4923 - loss: 1.0140Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.4917 - loss: 1.0139Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 300ms/step - accuracy: 0.4911 - loss: 1.0139Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 300ms/step - accuracy: 0.4904 - loss: 1.0140Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 300ms/step - accuracy: 0.4897 - loss: 1.0140Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 300ms/step - accuracy: 0.4891 - loss: 1.0139Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 300ms/step - accuracy: 0.4885 - loss: 1.0137Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.4880 - loss: 1.0135Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 299ms/step - accuracy: 0.4877 - loss: 1.0132Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 299ms/step - accuracy: 0.4872 - loss: 1.0131Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 300ms/step - accuracy: 0.4869 - loss: 1.0129Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 300ms/step - accuracy: 0.4867 - loss: 1.0126Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 300ms/step - accuracy: 0.4865 - loss: 1.0123Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.4865 - loss: 1.0120Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.4865 - loss: 1.0116Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.4866 - loss: 1.0111Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 300ms/step - accuracy: 0.4866 - loss: 1.0107Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 300ms/step - accuracy: 0.4866 - loss: 1.0103Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 300ms/step - accuracy: 0.4866 - loss: 1.0101Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.4866 - loss: 1.0099 Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.4864 - loss: 1.0098Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 300ms/step - accuracy: 0.4864 - loss: 1.0097Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - accuracy: 0.4864 - loss: 1.0095Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - accuracy: 0.4864 - loss: 1.0093Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - accuracy: 0.4865 - loss: 1.0091Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 300ms/step - accuracy: 0.4865 - loss: 1.0089Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 300ms/step - accuracy: 0.4864 - loss: 1.0088Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 300ms/step - accuracy: 0.4864 - loss: 1.0087Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 301ms/step - accuracy: 0.4863 - loss: 1.0085Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 301ms/step - accuracy: 0.4863 - loss: 1.0084Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 301ms/step - accuracy: 0.4862 - loss: 1.0083Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 301ms/step - accuracy: 0.4861 - loss: 1.0082Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 301ms/step - accuracy: 0.4861 - loss: 1.0081Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - accuracy: 0.4860 - loss: 1.0080Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - accuracy: 0.4859 - loss: 1.0079Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - accuracy: 0.4858 - loss: 1.0077Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 301ms/step - accuracy: 0.4858 - loss: 1.0075Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 301ms/step - accuracy: 0.4858 - loss: 1.0073Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 301ms/step - accuracy: 0.4858 - loss: 1.0071Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 301ms/step - accuracy: 0.4857 - loss: 1.0069Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 301ms/step - accuracy: 0.4857 - loss: 1.0068Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 301ms/step - accuracy: 0.4856 - loss: 1.0066Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 301ms/step - accuracy: 0.4855 - loss: 1.0065Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 300ms/step - accuracy: 0.4854 - loss: 1.0065Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.4852 - loss: 1.0064Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.4851 - loss: 1.0063Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - accuracy: 0.4851 - loss: 1.0061Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - accuracy: 0.4850 - loss: 1.0060Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 301ms/step - accuracy: 0.4850 - loss: 1.0057Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.4849 - loss: 1.0056Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.4849 - loss: 1.0054Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.4849 - loss: 1.0052Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 337ms/step - accuracy: 0.4849 - loss: 1.0048 - val_accuracy: 0.5471 - val_loss: 0.9309\n",
      "Epoch 20/20\n",
      "Training batch: 0\n",
      "Finished batch: 0\n",
      "\u001b[1m 1/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 299ms/step - accuracy: 0.3750 - loss: 1.0750Training batch: 1\n",
      "Finished batch: 1\n",
      "\u001b[1m 2/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 304ms/step - accuracy: 0.4062 - loss: 1.0043Training batch: 2\n",
      "Finished batch: 2\n",
      "\u001b[1m 3/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 299ms/step - accuracy: 0.4167 - loss: 0.9904Training batch: 3\n",
      "Finished batch: 3\n",
      "\u001b[1m 4/85\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 298ms/step - accuracy: 0.4297 - loss: 0.9829Training batch: 4\n",
      "Finished batch: 4\n",
      "\u001b[1m 5/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 295ms/step - accuracy: 0.4412 - loss: 0.9896Training batch: 5\n",
      "Finished batch: 5\n",
      "\u001b[1m 6/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 297ms/step - accuracy: 0.4528 - loss: 0.9900Training batch: 6\n",
      "Finished batch: 6\n",
      "\u001b[1m 7/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 296ms/step - accuracy: 0.4608 - loss: 0.9935Training batch: 7\n",
      "Finished batch: 7\n",
      "\u001b[1m 8/85\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 296ms/step - accuracy: 0.4686 - loss: 0.9926Training batch: 8\n",
      "Finished batch: 8\n",
      "\u001b[1m 9/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 295ms/step - accuracy: 0.4775 - loss: 0.9876Training batch: 9\n",
      "Finished batch: 9\n",
      "\u001b[1m10/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 295ms/step - accuracy: 0.4841 - loss: 0.9844Training batch: 10\n",
      "Finished batch: 10\n",
      "\u001b[1m11/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 295ms/step - accuracy: 0.4887 - loss: 0.9827Training batch: 11\n",
      "Finished batch: 11\n",
      "\u001b[1m12/85\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 295ms/step - accuracy: 0.4918 - loss: 0.9810Training batch: 12\n",
      "Finished batch: 12\n",
      "\u001b[1m13/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 295ms/step - accuracy: 0.4954 - loss: 0.9785Training batch: 13\n",
      "Finished batch: 13\n",
      "\u001b[1m14/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 296ms/step - accuracy: 0.4979 - loss: 0.9771Training batch: 14\n",
      "Finished batch: 14\n",
      "\u001b[1m15/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 296ms/step - accuracy: 0.4992 - loss: 0.9766Training batch: 15\n",
      "Finished batch: 15\n",
      "\u001b[1m16/85\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 295ms/step - accuracy: 0.5000 - loss: 0.9764Training batch: 16\n",
      "Finished batch: 16\n",
      "\u001b[1m17/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 296ms/step - accuracy: 0.5008 - loss: 0.9760Training batch: 17\n",
      "Finished batch: 17\n",
      "\u001b[1m18/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 299ms/step - accuracy: 0.5016 - loss: 0.9759Training batch: 18\n",
      "Finished batch: 18\n",
      "\u001b[1m19/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 301ms/step - accuracy: 0.5024 - loss: 0.9756Training batch: 19\n",
      "Finished batch: 19\n",
      "\u001b[1m20/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 302ms/step - accuracy: 0.5027 - loss: 0.9757Training batch: 20\n",
      "Finished batch: 20\n",
      "\u001b[1m21/85\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 302ms/step - accuracy: 0.5030 - loss: 0.9759Training batch: 21\n",
      "Finished batch: 21\n",
      "\u001b[1m22/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 301ms/step - accuracy: 0.5029 - loss: 0.9765Training batch: 22\n",
      "Finished batch: 22\n",
      "\u001b[1m23/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 301ms/step - accuracy: 0.5029 - loss: 0.9770Training batch: 23\n",
      "Finished batch: 23\n",
      "\u001b[1m24/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 301ms/step - accuracy: 0.5031 - loss: 0.9773Training batch: 24\n",
      "Finished batch: 24\n",
      "\u001b[1m25/85\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 301ms/step - accuracy: 0.5034 - loss: 0.9772Training batch: 25\n",
      "Finished batch: 25\n",
      "\u001b[1m26/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 300ms/step - accuracy: 0.5039 - loss: 0.9772Training batch: 26\n",
      "Finished batch: 26\n",
      "\u001b[1m27/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 300ms/step - accuracy: 0.5043 - loss: 0.9770Training batch: 27\n",
      "Finished batch: 27\n",
      "\u001b[1m28/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 300ms/step - accuracy: 0.5046 - loss: 0.9768Training batch: 28\n",
      "Finished batch: 28\n",
      "\u001b[1m29/85\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 300ms/step - accuracy: 0.5049 - loss: 0.9767Training batch: 29\n",
      "Finished batch: 29\n",
      "\u001b[1m30/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 300ms/step - accuracy: 0.5050 - loss: 0.9766Training batch: 30\n",
      "Finished batch: 30\n",
      "\u001b[1m31/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 300ms/step - accuracy: 0.5051 - loss: 0.9769Training batch: 31\n",
      "Finished batch: 31\n",
      "\u001b[1m32/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.5052 - loss: 0.9772Training batch: 32\n",
      "Finished batch: 32\n",
      "\u001b[1m33/85\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.5054 - loss: 0.9776Training batch: 33\n",
      "Finished batch: 33\n",
      "\u001b[1m34/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.5056 - loss: 0.9779Training batch: 34\n",
      "Finished batch: 34\n",
      "\u001b[1m35/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 300ms/step - accuracy: 0.5057 - loss: 0.9781Training batch: 35\n",
      "Finished batch: 35\n",
      "\u001b[1m36/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 302ms/step - accuracy: 0.5058 - loss: 0.9785Training batch: 36\n",
      "Finished batch: 36\n",
      "\u001b[1m37/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 303ms/step - accuracy: 0.5059 - loss: 0.9788Training batch: 37\n",
      "Finished batch: 37\n",
      "\u001b[1m38/85\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 303ms/step - accuracy: 0.5060 - loss: 0.9794Training batch: 38\n",
      "Finished batch: 38\n",
      "\u001b[1m39/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 303ms/step - accuracy: 0.5059 - loss: 0.9799Training batch: 39\n",
      "Finished batch: 39\n",
      "\u001b[1m40/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 303ms/step - accuracy: 0.5058 - loss: 0.9804Training batch: 40\n",
      "Finished batch: 40\n",
      "\u001b[1m41/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 303ms/step - accuracy: 0.5057 - loss: 0.9809Training batch: 41\n",
      "Finished batch: 41\n",
      "\u001b[1m42/85\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 303ms/step - accuracy: 0.5057 - loss: 0.9815Training batch: 42\n",
      "Finished batch: 42\n",
      "\u001b[1m43/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 303ms/step - accuracy: 0.5057 - loss: 0.9822Training batch: 43\n",
      "Finished batch: 43\n",
      "\u001b[1m44/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 303ms/step - accuracy: 0.5057 - loss: 0.9827Training batch: 44\n",
      "Finished batch: 44\n",
      "\u001b[1m45/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 303ms/step - accuracy: 0.5057 - loss: 0.9832Training batch: 45\n",
      "Finished batch: 45\n",
      "\u001b[1m46/85\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 302ms/step - accuracy: 0.5056 - loss: 0.9836Training batch: 46\n",
      "Finished batch: 46\n",
      "\u001b[1m47/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.5055 - loss: 0.9842Training batch: 47\n",
      "Finished batch: 47\n",
      "\u001b[1m48/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 303ms/step - accuracy: 0.5053 - loss: 0.9848Training batch: 48\n",
      "Finished batch: 48\n",
      "\u001b[1m49/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 303ms/step - accuracy: 0.5052 - loss: 0.9854Training batch: 49\n",
      "Finished batch: 49\n",
      "\u001b[1m50/85\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 302ms/step - accuracy: 0.5051 - loss: 0.9860Training batch: 50\n",
      "Finished batch: 50\n",
      "\u001b[1m51/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 302ms/step - accuracy: 0.5050 - loss: 0.9865Training batch: 51\n",
      "Finished batch: 51\n",
      "\u001b[1m52/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5048 - loss: 0.9871 Training batch: 52\n",
      "Finished batch: 52\n",
      "\u001b[1m53/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5046 - loss: 0.9877Training batch: 53\n",
      "Finished batch: 53\n",
      "\u001b[1m54/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 302ms/step - accuracy: 0.5045 - loss: 0.9882Training batch: 54\n",
      "Finished batch: 54\n",
      "\u001b[1m55/85\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 304ms/step - accuracy: 0.5044 - loss: 0.9887Training batch: 55\n",
      "Finished batch: 55\n",
      "\u001b[1m56/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.5043 - loss: 0.9890Training batch: 56\n",
      "Finished batch: 56\n",
      "\u001b[1m57/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 303ms/step - accuracy: 0.5042 - loss: 0.9895Training batch: 57\n",
      "Finished batch: 57\n",
      "\u001b[1m58/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 304ms/step - accuracy: 0.5040 - loss: 0.9899Training batch: 58\n",
      "Finished batch: 58\n",
      "\u001b[1m59/85\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 304ms/step - accuracy: 0.5039 - loss: 0.9904Training batch: 59\n",
      "Finished batch: 59\n",
      "\u001b[1m60/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.5037 - loss: 0.9908Training batch: 60\n",
      "Finished batch: 60\n",
      "\u001b[1m61/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 303ms/step - accuracy: 0.5034 - loss: 0.9912Training batch: 61\n",
      "Finished batch: 61\n",
      "\u001b[1m62/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - accuracy: 0.5032 - loss: 0.9916Training batch: 62\n",
      "Finished batch: 62\n",
      "\u001b[1m63/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - accuracy: 0.5030 - loss: 0.9918Training batch: 63\n",
      "Finished batch: 63\n",
      "\u001b[1m64/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - accuracy: 0.5028 - loss: 0.9921Training batch: 64\n",
      "Finished batch: 64\n",
      "\u001b[1m65/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 303ms/step - accuracy: 0.5026 - loss: 0.9924Training batch: 65\n",
      "Finished batch: 65\n",
      "\u001b[1m66/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.5023 - loss: 0.9927Training batch: 66\n",
      "Finished batch: 66\n",
      "\u001b[1m67/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.5020 - loss: 0.9931Training batch: 67\n",
      "Finished batch: 67\n",
      "\u001b[1m68/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.5018 - loss: 0.9933Training batch: 68\n",
      "Finished batch: 68\n",
      "\u001b[1m69/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 302ms/step - accuracy: 0.5015 - loss: 0.9936Training batch: 69\n",
      "Finished batch: 69\n",
      "\u001b[1m70/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 302ms/step - accuracy: 0.5013 - loss: 0.9939Training batch: 70\n",
      "Finished batch: 70\n",
      "\u001b[1m71/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m4s\u001b[0m 302ms/step - accuracy: 0.5010 - loss: 0.9942Training batch: 71\n",
      "Finished batch: 71\n",
      "\u001b[1m72/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m3s\u001b[0m 302ms/step - accuracy: 0.5008 - loss: 0.9945Training batch: 72\n",
      "Finished batch: 72\n",
      "\u001b[1m73/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 304ms/step - accuracy: 0.5005 - loss: 0.9948Training batch: 73\n",
      "Finished batch: 73\n",
      "\u001b[1m74/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 304ms/step - accuracy: 0.5002 - loss: 0.9952Training batch: 74\n",
      "Finished batch: 74\n",
      "\u001b[1m75/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 304ms/step - accuracy: 0.4999 - loss: 0.9955Training batch: 75\n",
      "Finished batch: 75\n",
      "\u001b[1m76/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m2s\u001b[0m 304ms/step - accuracy: 0.4996 - loss: 0.9958Training batch: 76\n",
      "Finished batch: 76\n",
      "\u001b[1m77/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 303ms/step - accuracy: 0.4993 - loss: 0.9961Training batch: 77\n",
      "Finished batch: 77\n",
      "\u001b[1m78/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 303ms/step - accuracy: 0.4991 - loss: 0.9964Training batch: 78\n",
      "Finished batch: 78\n",
      "\u001b[1m79/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 0.4988 - loss: 0.9967Training batch: 79\n",
      "Finished batch: 79\n",
      "\u001b[1m80/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 0.4985 - loss: 0.9970Training batch: 80\n",
      "Finished batch: 80\n",
      "\u001b[1m81/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 303ms/step - accuracy: 0.4982 - loss: 0.9973Training batch: 81\n",
      "Finished batch: 81\n",
      "\u001b[1m82/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.4979 - loss: 0.9976Training batch: 82\n",
      "Finished batch: 82\n",
      "\u001b[1m83/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.4977 - loss: 0.9978Training batch: 83\n",
      "Finished batch: 83\n",
      "\u001b[1m84/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.4975 - loss: 0.9980Training batch: 84\n",
      "Finished batch: 84\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 340ms/step - accuracy: 0.4970 - loss: 0.9985 - val_accuracy: 0.4882 - val_loss: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x225831fa200>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(ds_train,\n",
    "          validation_data=ds_val,\n",
    "          epochs=20,\n",
    "          callbacks=[debug_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d8ddf87-579f-4201-ac77-bdc94afdf166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 255ms/step - accuracy: 0.5483 - loss: 0.8997\n",
      "Test Loss: 0.8910624980926514, Test Accuracy: 0.5176470875740051\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate(ds_test)\n",
    "print(f\"Test Loss: {eval_results[0]}, Test Accuracy: {eval_results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd87d5-368a-43f3-97d3-af94671da6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
